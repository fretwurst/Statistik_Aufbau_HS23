<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de-CH" xml:lang="de-CH"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Statistik Aufbau - 2&nbsp; Das lineare Modell</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./03_Regression_in_R.html" rel="next">
<link href="./01_Wiederholung.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Keine Treffer",
    "search-matching-documents-text": "Treffer",
    "search-copy-link-title": "Link in die Suche kopieren",
    "search-hide-matches-text": "Zusätzliche Treffer verbergen",
    "search-more-match-text": "weitere Treffer in diesem Dokument",
    "search-more-matches-text": "weitere Treffer in diesem Dokument",
    "search-clear-button-title": "Zurücksetzen",
    "search-detached-cancel-button-title": "Abbrechen",
    "search-submit-button-title": "Abschicken"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="www/style.css">
<link rel="stylesheet" href="www/webex.css">
<link rel="stylesheet" href="www/index.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Das lineare Modell</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistik Aufbau</a> 
        <div class="sidebar-tools-main">
    <a href="./Statistik-Aufbau---Fretwurst.pdf" title="Download PDF" class="sidebar-tool px-1"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Einleitung</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_Wiederholung.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Was bisher geschah</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_GLM.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Das lineare Modell</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_Regression_in_R.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Regression in R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_Gruppenvergleiche.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Gruppenvergleiche (ANCOVA)</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_Dimensionsreduktion.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Faktorenanalyse</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_ML.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Machine Learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_Clusteranalyse.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Clusteranalyse</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./80_Glossar.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Glossar</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./90_Literatur.html" class="sidebar-item-text sidebar-link">Literatur</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Seiteninhalt</h2>
   
  <ul>
  <li><a href="#varianzanalyse" id="toc-varianzanalyse" class="nav-link active" data-scroll-target="#varianzanalyse"><span class="toc-section-number">2.1</span>  Varianzanalyse</a></li>
  <li><a href="#regression" id="toc-regression" class="nav-link" data-scroll-target="#regression"><span class="toc-section-number">2.2</span>  Regression</a>
  <ul class="collapse">
  <li><a href="#das-modell-und-die-regressionsgleichung-als-schätzung" id="toc-das-modell-und-die-regressionsgleichung-als-schätzung" class="nav-link" data-scroll-target="#das-modell-und-die-regressionsgleichung-als-schätzung"><span class="toc-section-number">2.2.1</span>  Das Modell und die Regressionsgleichung als Schätzung</a></li>
  <li><a href="#ols" id="toc-ols" class="nav-link" data-scroll-target="#ols"><span class="toc-section-number">2.2.2</span>  OLS</a></li>
  <li><a href="#bs" id="toc-bs" class="nav-link" data-scroll-target="#bs"><span class="toc-section-number">2.2.3</span>  B’s</a></li>
  <li><a href="#das-bestimttheitsmass-r2" id="toc-das-bestimttheitsmass-r2" class="nav-link" data-scroll-target="#das-bestimttheitsmass-r2"><span class="toc-section-number">2.2.4</span>  Das Bestimttheitsmass <span class="math inline">\(R^2\)</span></a></li>
  <li><a href="#kennwerte-der-regression" id="toc-kennwerte-der-regression" class="nav-link" data-scroll-target="#kennwerte-der-regression"><span class="toc-section-number">2.2.5</span>  Kennwerte der Regression</a></li>
  </ul></li>
  <li><a href="#vorraussetzung-für-blue" id="toc-vorraussetzung-für-blue" class="nav-link" data-scroll-target="#vorraussetzung-für-blue"><span class="toc-section-number">2.3</span>  Vorraussetzung für BLUE</a>
  <ul class="collapse">
  <li><a href="#variablenskalierung-v1.-v2." id="toc-variablenskalierung-v1.-v2." class="nav-link" data-scroll-target="#variablenskalierung-v1.-v2."><span class="toc-section-number">2.3.1</span>  Variablenskalierung (V1.-V2.)</a></li>
  <li><a href="#modellspezifikation-und-multikollinearität-v3.-v5." id="toc-modellspezifikation-und-multikollinearität-v3.-v5." class="nav-link" data-scroll-target="#modellspezifikation-und-multikollinearität-v3.-v5."><span class="toc-section-number">2.3.2</span>  Modellspezifikation und Multikollinearität (V3.-V5.)</a></li>
  <li><a href="#homoskedastizität-v6." id="toc-homoskedastizität-v6." class="nav-link" data-scroll-target="#homoskedastizität-v6."><span class="toc-section-number">2.3.3</span>  Homoskedastizität (V6.)</a></li>
  <li><a href="#verteilung-der-residuen-v7.-und-v8." id="toc-verteilung-der-residuen-v7.-und-v8." class="nav-link" data-scroll-target="#verteilung-der-residuen-v7.-und-v8."><span class="toc-section-number">2.3.4</span>  Verteilung der Residuen (V7. und V8.)</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Das lineare Modell</span></h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Veröffentlichungsdatum</div>
    <div class="quarto-title-meta-contents">
      <p class="date">1. September 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<p>Das lineare Modell ist die Basis von fast allem. Auch was Sie schon kennen, wird unter dem Konzept «lineares Modell» zusammengefasst:</p>
<ul>
<li>Varianzanalyse</li>
<li>Korrelation</li>
<li>Regression</li>
</ul>
<p>Das lineare Modell ist auch nicht auf lineare Zusammenhänge beschränkt. Es kann sehr gut mit kurvilinearen Zusammenhängen umgehen. Also, wenn zum Beispiel bei einer Gesamtnachrichtenlage mit sehr hohem Nachrichtenwert der Umfang des Medienkonsums steigt. Irgendwann erfährt diese Wirkung einen Deckeneffekt, weil niemand auf Dauer 24h am Tag Medien konsumieren kann. Vielleicht steigt der Nachrichtenkonsum mit dem Nachrichtenwert sogar Anfangs exponentiell (wie Coronazahlen) und hat dann bald einen Umkehrpunkt und strebt gegen ein mögliches Maximum. Selbst solche komplexeren Zusammenhänge können in einem linearen Modell dargestellt werden.</p>
<p>Die höhere Statistik wie Faktorenanalysen, Strukturgleichungsmodelle, Zeitreihenanalysen (Forcastings oder Laten-Growth-Curve-Modelle) bauen alle auf dem linearen Modell auf. Und auch Computational Science nutzt Modelle und zwar überwiegend als Basis die linearen Modelle.</p>
<hr>
<p><strong>Welche der folgenden Analysemethoden gehören zum linearen Modell?</strong></p>
<div class="cell" data-hash="02_GLM_cache/html/unnamed-chunk-2_383aeb975f14a47ab9270dd3cd9cbf68">

</div>
<div id="radio_MWLEFOODFI" class="webex-radiogroup">
<label><input type="radio" autocomplete="off" name="radio_MWLEFOODFI" value="answer"> <span>Regression</span></label><label><input type="radio" autocomplete="off" name="radio_MWLEFOODFI" value="answer"> <span>Varianzanalyse</span></label><label><input type="radio" autocomplete="off" name="radio_MWLEFOODFI" value=""> <span>Faktorenanalyse</span></label><label><input type="radio" autocomplete="off" name="radio_MWLEFOODFI" value=""> <span>Korrelation</span></label>
</div>
<hr>
<section id="varianzanalyse" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="varianzanalyse"><span class="header-section-number">2.1</span> Varianzanalyse</h2>
<p>Bei der Varianzanalyse werden Streuungen zerlegt. Das bedeutet, dass die Unterschiede zwischen den Fällen (z.B. Personen) in Bezug auf eine Variable (z.B. Links-Rechts-Spektrum) einen Mittelwert (Durchschnitt) haben und Abweichungen von diesem Mittelwert. Da die Abweichungen von einer Mitte negativ sind (links vom Mittel) und positiv sind (rechts vom Mittel) würde sich eine Summe aus allen Mittelwertabweichungen auf 0 aufaddieren – darum ja eben auch Mittelwert, weil er in der Mitte liegt. Darum nehmen wir von den Mittelwertabweichungen immer das Quadrat. Die Quadrate (Minus * Minus = Plus und Plus * Plus = Plus) ergeben in der Summe einen positiven Wert und wenn man den durch die Anzahl n der Fälle teilt, dann hat man die Varianz. Anders gesagt: Die Varianz ist die durchschnittliche quadrierte Mittelwertabweichung (so steht’s ja auch schon oben).</p>
<p>Bei der Varianzanalyse teilen wir unsere Stichprobe in Unterstichproben auf, also z.B. anhand von zwei Gruppen, wie Stadtbevölkerung und Landbevölkerung und schauen dann wo die Stadtbevölkerung im Mittelwert auf der Links-Rechts-Skala liegt und wo die Landbevölkerung im Mittel der Links-Rechts-Skala liegt. Mit hoher Sicherheit werden sich die Mittelwerte unterscheiden. Nimmt man nun die Varianz der Landbevölkerung um ihren Mittelwert und die Varianz der Stadtbevölkerung um ihren Mittelwert und addiert die zusammen, kommt ein kleinerer Wert heraus, als wenn man die Varianz für die Links-Rechts-Skala berechnet (nur wenn beide Mittelwerte identisch wären, wäre auch die Summe der Varianzen identisch), ohne die Unterscheidung zwischen Stadt und Land zu machen. Der Wert wird immer kleiner, je weiter die beiden Mittelwerte voneinander entfernt liegen. Wenn für die Links-Rechts-Skala die Summe der Varianzen der beiden Gruppen deutlich kleiner ist als die Gesamtvarianz, dann hat die Unterscheidung zwischen Stadt- und Landbevölkerung Varianz «aufgeklärt». Das ist Varianzaufklärung und die Basis der Varianzanalyse. Es geht kurz gesagt darum, ob die Unterschiede in einer Variable gross sind, weil sie durch eine andere Variable bedingt werden, für die die Varianz zerlegt wird. Darum sagt man auch «Varianzzerlegung». Wir werden uns das noch ausführlich bis genüsslich anschauen in diesem Semester.</p>
<hr>
<p>Hier können Sie mit einer kleinen Onlineapp mit einer ANOVA (<strong>AN</strong>alysis <strong>O</strong>f <strong>VA</strong>riance) interaktiv herumprobieren:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://saskiaotto.de/shiny/anova/"><img src="images/shiny-ANOVA.jpg" title="Link zu ANOVA-App" class="img-fluid figure-img" style="width:100.0%"></a></p>
<p></p><figcaption class="figure-caption">ANOVA</figcaption><p></p>
</figure>
</div>
<hr>
<p>Nun stellen Sie sich vor, Sie machen eine Auswertung und haben eine Variable die Sie erklären wollen, also eine abhängige Variable (AV), wie z.B. die Verweildauer auf TikTok-Videos. Die erklären Sie damit, wie viel Spass jemand an einem gezeigten Video hat. Sie könnten den Spass einteilen in «kein Spass», «wenig Spass» und «viel Spass». Dann könnten Sie für die drei Gruppen eine Varianzanalyse rechnen, testen Ihre Hypothesen mit t-Tests oder einer One-Way-Anova und kommen anhand der t-Werte oder auch F-Werte zu einer Entscheidung über statistische Hypothese: Der Zusammenhang ist signifikant oder nicht. Ok. – Wenn das «lineare Modell» Varianzanalyse ist und Regression, dann müsste man doch dieselbe Analyse mit einer Regression machen können. Und ja, das kann man. Und es kommen ganz genau dieselben Ergebnisse raus: Dieselben t-Werte, dieselben F-Werte und natürlich, darauf fussend, dieselben p-Werte (Wahrscheinlichkeit, dass die t- und F-Werte zustandekommen, obwohl die Nullhypothese gilt). Wir probieren das mal: Und es wäre extrem peinlich für mich, wenn da unterschiedliche Werte rauskommen – aufregend!</p>
<p>In R kann man mit Extrapaketen auch Varianzanalysen machen. Es gibt aber keine Pakete für Regressionen. Das liegt daran, dass das lineare Modell (lm) in R die Regression ist! Wir werden uns im ersten Teil des Moduls also mit dem linearen Modell auseinandersetzen.</p>
</section>
<section id="regression" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="regression"><span class="header-section-number">2.2</span> Regression</h2>
<p>Die Regression ist das einfachste und gleichzeitig mächtigste Werkzeug multivariater Datenanalyse. Aus den Kovarianzen mehrerer Variablen wird eine Funktion mit wenigen Kennwerten berechnet. Diese Kennwerte als Einzelwerte geben Auskunft über die Zusammenhänge zwischen einzelnen Prädiktoren und einer abhängigen Variablen. Man muss also vorher sagen, was man erklären will und womit man es erklären will. Die zu erklärende Grösse nennt man in der Sozialwissenschaft (und anderen Disziplinen): abhängige Variable (AV oder DV) und die Erklärungsgrössen nennt man: unabhängige Variablen (UV oder IV).</p>
<p>Die Regression baut auf Kovarianzen auf (bzw. Korrelationen, die wir uns besser vorstellen können). Die Regressionsgerade wird bei einer bivariaten Regression durch eine Konstante (in der Abbildung @ref(fig:KorrelationRegression) ist sie 1) und einem Anstieg je Variable gekennzeichnet (in der Abbildung ist es 0,5 für die eine UV = x).</p>
<div class="cell" data-hash="02_GLM_cache/html/KorrelationRegression_f1e9c4a8d63e82dd8a442210cabc4911">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Korrelation_Regression.jpg" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Von der Korrelation zur Regression</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Das bedeutet, dass bei einer bivariaten Regression zwei b’s die Lage der Regressionsgeraden bestimmen: Das ist zum einen die Konstante <span class="math inline">\(b_1\)</span> und zum anderen der Anstieg <span class="math inline">\(b_2\)</span> für die Gerade. In der Abbildung @ref(fig:RegressionsGeraden) sehen Sie links zwei Regressionsgeraden mit unterschiedlichen <span class="math inline">\(b_2\)</span> (rot positiv und grün negativ). Auf der rechten Seite sehen Sie drei Regressionsgeraden mit unterschiedlichen <span class="math inline">\(b_1\)</span>, wobei das b der roten Gerade am grössten ist (knapp 70), grün am kleinsten (bischen über 20) und blau in der Mitte liegt (knapp 40).</p>
<div class="cell" data-hash="02_GLM_cache/html/RegressionsGeraden_c1b0f76e4ead696db63b67f05768f456">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Regressionsgeraden.jpg" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">B’s bei bivariaten Regressionen</figcaption><p></p>
</figure>
</div>
</div>
</div>
<hr>
<p><strong>Welche Funktion und Eigenschaften haben die Regressionskoeffizienten b?</strong></p>
<div class="cell" data-hash="02_GLM_cache/html/unnamed-chunk-3_6d802897a0b4e610d20d41787838a79f">

</div>
<div id="radio_EEXOMBWKKE" class="webex-radiogroup">
<label><input type="radio" autocomplete="off" name="radio_EEXOMBWKKE" value="answer"> <span>Wenn verschiedene Regressionsgeraden den selben Anstieg haben, dann ist ihr b gleich.</span></label><label><input type="radio" autocomplete="off" name="radio_EEXOMBWKKE" value="answer"> <span><span class="math inline">\(b_2\)</span> gibt in der Regression den Anstieg der Regressionsgerade für die UV <span class="math inline">\(x_2\)</span> an.</span></label><label><input type="radio" autocomplete="off" name="radio_EEXOMBWKKE" value=""> <span><span class="math inline">\(b_3\)</span> ist eine Konstante, die den Schnittpunkt mit der y-Achse angibt (engl. intercept)</span></label><label><input type="radio" autocomplete="off" name="radio_EEXOMBWKKE" value=""> <span>Wenn b = 1, dann ist der Zusammenhang perfekt.</span></label>
</div>
<hr>
<!-- ::: {.infobox .caution data-latex="{caution}"} -->
<!-- **?:** -->
<!-- **!:** -->
<!-- Thank you for noticing this **new notice**! Your noticing it has -->
<!-- been noted, and _will be reported to the authorities_! -->
<!-- ::: -->
<section id="das-modell-und-die-regressionsgleichung-als-schätzung" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="das-modell-und-die-regressionsgleichung-als-schätzung"><span class="header-section-number">2.2.1</span> Das Modell und die Regressionsgleichung als Schätzung</h3>
<p>Die formelle Schreibweise eines Regressionsmodells enthält griechische Buchstaben um zu signalisieren, dass es sich hier um unbekannte Grössen, die Parameter in der Grundgesamtheit, handelt. So lange wir über die Qualität und die Eigenschaften von Regressionsrechnungen sprechen, wird uns der Unterschied zwischen <span class="math inline">\(\beta\)</span>’s und b’s interessieren.</p>
<p>Als Gleichung heisst das, dass die Abhängige Variable <span class="math inline">\(Y_i\)</span> durch eine gewichtete Summe (siehe Formel @ref(eq:RegressionParameter)) von einer oder mehreren unabhängigen Variablen erklärt wird. Diese UVs werden in der Regel mit X gekennzeichnet und weil es mehrere davon geben kann, werden sie durchnummeriert. Also mit dem Subscript i für das Durchzählen werden sie griechisch für die Parameter als <span class="math inline">\(\beta_2X_{i2}\)</span> bezeichnet oder eben als <span class="math inline">\(\beta_3X_{i3}\)</span> usw. Dann gibt es noch den Rest <span class="math inline">\(U_i\)</span>. Das ist also das theoretische statistische Modell, dessen Parameter wir mit Kennwerten schätzen wollen.</p>
<span class="math display">\[\begin{align}
   Y_i&amp;=\beta_1 + \beta_2X_{i2} + \beta_3X_{i3} + U_i \label{eq:RegressionParameter}
\end{align}\]</span>
<p>Wenn man mal genau schaut was hier eigentlich noch variabel ist, nach der Stichprobenziehung, dann wird klar, dass die <span class="math inline">\(Y_i\)</span> ja in der Datenerhebung gemessen wurden und damit Werte enthalten, die wir statistisch nicht mehr ändern. Das Gleiche gilt für die <span class="math inline">\(X_i\)</span>-Werte der Variablen <span class="math inline">\(X_2\)</span> und <span class="math inline">\(X_3\)</span>. Also sind diese Grössen eigentlich keine «Variablen» mehr, sondern längst durch echte Werte fixiert. Zu schätzen sind nur die Bs, also <span class="math inline">\(b_1\)</span>, <span class="math inline">\(b_2\)</span> und <span class="math inline">\(b_3\)</span> (übrigens nummerieren wir die so durch, weil sie später als Vektor in der Matrizenrechnung die erste Zeile belegen, die zweite und dritte usw.). Wenn wir die Regressionskoeffizienten, die b’s in unserer Stichprobe, berechnet haben, müssen wir uns noch fragen, wie gut, also unverzerrt und genau sie die unbekannten Parameter (<span class="math inline">\(\beta\)</span>s) messen, also – etwas technischer ausgedrückt – ob die b die <span class="math inline">\(\beta\)</span> erwartungstreu und effizient schätzen. Dafür gibt es einige Voraussetzungen, die wir uns später [in Kapitel noch nicht da] noch anschauen werden. Am Ende der Formel steht das <span class="math inline">\(e_i\)</span> für die Fehler, also den unerklärten Rest der Varianz, der zwischen den durch das Modell geschätzten Werten (gekennzeichnet mit einem Dach als <span class="math inline">\(\hat{Y_i}\)</span>) und den gemessenen Werten liegt. Während die s’s die Schätzer für die <span class="math inline">\(\beta\)</span>s sind, ist das <span class="math inline">\(e_i\)</span> kein Schätzer für <span class="math inline">\(U_i\)</span>. Das liegt daran, dass das <span class="math inline">\(e_i\)</span> nur eine Fehlerstreuung in der Stichprobe ist und <span class="math inline">\(U_i\)</span> viel mehr angibt, dass unberücksichtigte Einflussgrössen und ein stochastischer Rest nicht vom Modell abgebildet sind.</p>
<span class="math display">\[\begin{align}
Y_i&amp;=b_1 + b_2X_{i2} + b_3X_{i3}+e_i
\end{align}\]</span>
<p>Bei einer Regression mit zwei UVs wird praktisch eine Ebene in die Punktwolke gelegt (siehe @ref(fig:Regressionsebene)). Wir schätzen aber eine multivariate Regression, damit wir bivariat interpretieren können, also je UV sagen, wie stark der Effekt auf die AV ist. Insofern interpretieren wir je Variable nur ein b oder ein (BETA), was dem Ansteig (Zusammenhang) einer Variablen entspricht. Das können wir machen, weil die Statistik bzw. unser Statistikprogramm für uns die Kontrolle der übrigen Variablen übernimmt und wir schön die kontrollierte bivariate Beziehung interpretieren können. Die b’s beschreiben dabei die Gerade, die die Ebene an der Stelle bildet, die für die andere Variable der Durchschnitt ist. Bei drei UVs spannen die b’s zusammen eigentlich einen Raum auf, was sich aber niemand mehr visuell vorstellen kann. Die Statistik kann das aber und erledigt das so für uns, dass wir uns immer nur die Beziehungen anhand der jeweiligen b’s der einzelnen UV’s anschauen können.</p>
<div class="cell" data-hash="02_GLM_cache/html/Regressionsebene_b86484bd93ce4f92c34da4de2254f30f">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/IV_Regression.png" class="img-fluid figure-img" style="width:75.0%"></p>
<p></p><figcaption class="figure-caption">R-Quadrat</figcaption><p></p>
</figure>
</div>
</div>
</div>
<hr>
<p>Hier wird eine Regression recht gut als Punktwolke visualisiert: <a href="http://shiny.calpoly.sh/3d_regression/" class="uri">http://shiny.calpoly.sh/3d_regression/</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="http://shiny.calpoly.sh/3d_regression/"><img src="images/Regression-bivariat.jpg" title="Link zu Regressionsapp" class="img-fluid figure-img" style="width:100.0%"></a></p>
<p></p><figcaption class="figure-caption">Regression</figcaption><p></p>
</figure>
</div>
<hr>
<hr>
<p><strong>Schreiben Sie die Formel für die einfache bivariate Regression auf?</strong></p>
<div class="webex-solution">
<button>
Lösung anschauen
</button>
<span class="math display">\[\begin{align}
Y_i&amp;=b_1 + b_2X_{i2} +e_i
\end{align}\]</span>
</div>
<hr>
</section>
<section id="ols" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="ols"><span class="header-section-number">2.2.2</span> OLS</h3>
<p>Eine der einfacheren und grundlegenden Methoden um die b’s zu bestimmen ist die Methode der kleinsten Quadrate bzw. OLS, was das Akronym für <strong>O</strong>rdinary <strong>L</strong>east <strong>S</strong>quares ist. Mit dieser Methode legt die Mathematik eine Gerade in eine Punktwolke, weil sie es nicht visuell und intuitiv machen kann. Das Prinzip ist recht einfach: Man versucht b’s zu finden, für die die Fehler möglichst klein sind. Das ist im Grunde die Optimierungsaufgabe der OLS-Methode. Genau das machen wir auch, wenn wir eine Gerade in eine Punktwolke legen, wir bauen sie so ein, dass sie «optimal reinpasst» also die Abstände zu den einzelnen Punkten minimal sind.</p>
<hr>
<p><strong>Sehr gut hier zum anschauen und spielen:</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://econometricsbysimulation.shinyapps.io/OLS-App/"><img src="images/shiny-OLS.jpg" title="Link zur OLS-App" class="img-fluid figure-img" style="width:100.0%"></a></p>
<p></p><figcaption class="figure-caption">OLS-App</figcaption><p></p>
</figure>
</div>
<hr>
<p>Als Beispiel hatte ich in der Vorlesung gebracht, dass man auch mal überlegen könnte, welcher Wert eine Verteilung einer Variablen optimal repräsentieren würde. Wenn wir dieses Optimierungsproblem an OLS übergeben würden, dann würden wir sagen: Suche einen Wert a aus allen möglichen a-Werten, der für eine Variable x die kleinsten quadrierten Abstände hat. Damit es OLS versteht würden wir schreiben: <span class="math inline">\(\text{OLS bitte minimiere folgende Gleichung:} \sum_i{(x_i-a)^2}\)</span></p>
<p>Jetzt wissen wir, dass die quadrierten Abweichungen gross sein müssen, wenn a links vom Optimum liegt und immer kleiner wird, wenn wir uns dem optimalen a-Wert annähern. Dann wird die Summe der quadratischen Abstände wieder grösser. Also haben wir eine Funktion, die einer quadratischen Funktion folgt (dass die so aussieht, müssen wir garnicht wissen, aber es hilft vielleicht der Vorstellung). Wenn wir wissen wollen, wo diese Funktion ihr Minimum hat, dann können wir die Funktion ableiten und dann nach der Nullstelle der abgeleiteten Funktion suchen. An der Stelle liegt dann der a-Wert, der die Streuung einer jeden Variablen optimal abbildet, weil wir diese Ableitung völlig abstrakt und ohne konkrete Werte gemacht haben und sie daher immer gilt. Also:</p>
<span class="math display">\[\begin{align}
  \frac{df}{da} = &amp; \sum_i{(x_i-a)^2}^{\prime} = 0 \label{eq:OLS-Ableitung} \\
  0 = &amp; \sum_i{[x_i^2 - 2x_ia + a^2]}^{\prime} \label{eq:OLS-Ableitung2}
\end{align}\]</span>
<p>In der ersten Zeile das df/da bedeutet, dass abgeleitet (differenziert) werden soll und zwar die Funktion f nach a. In der zweiten Zeile sehen wir dann schon die Ableitung nach Ableitungsregeln (wer extrem Bock hat, kann sich die ja nochmal angucken) und gleich auch schon mit 0 gleichgesetzt.</p>
<p>In der nächsten Zeile @ref(eq:Umstellen1) wird ein bischen aufgelöst und umgestellt (müssen Sie nicht können).</p>
<span class="math display">\[\begin{align}
  0 = &amp; -2\sum_i{x_i} + 2na &amp; |:2n\ |+\sum_i{x_i} \label{eq:Umstellen1}\\
  \frac{\sum_i{x_i}}{n} = &amp; a \label{eq:Umstellen2} \\
  a = &amp;\overline{x} \label{eq:Mittelwert-Optimum}
\end{align}\]</span>
<p>Am Ende kommt als Lösung für den nach OLS besten Repräsentanten einer Variablen heraus: <span class="math inline">\(\frac{\sum_i{x_i}}{n} = a\)</span> @ref(eq:Umstellen2). Der linke Teil ist genau die Definition von <span class="math inline">\(\overline{x}\)</span>, also dem Mittelwert. Damit haben wir mit einer Ableitungen der OLS herausgefunden, dass der Mittelwert die kleinste Summe der quadrierten Abstände jedes Wertes zu einem Wert a hat, also der gesuchte beste Repräsentant für eine Variable der Wert <span class="math inline">\(a=\overline{x}\)</span> ist @ref(eq:Mittelwert-Optimum). Dasselbe könnten wir für die Formel <span class="math inline">\(Y_i = b_1 + b_2X_i + e_i\)</span> machen. Wenn wir (mit ein paar Annahmen) das für jedes <span class="math inline">\(b_1\)</span> bis <span class="math inline">\(b_3\)</span> machen würden, dann hätten wir die b’s mit OLS bestimmt. Da das ungleich komplizierter ist als für den Mittelwert, schlage ich vor, wir lassen das an dieser Stelle.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
IYI (nur für Formelliebende): Ableitung der OLS-Funktion
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Ausgangspunkt für die Ableitung der OLS-Funktion ist die Idee, den vom Modell nicht erklärten Rest, also die Residuen (<span class="math inline">\(e_i\)</span>) zu minimieren. Die Residuen sind wie folgt definiert:</p>
<p><span id="eq-2.4"><span class="math display">\[
e_i=Y_i-\hat{Y}_i=Y_i-b_1-b_2 X_{i 2}-b_3 X_{i 3}
\tag{2.1}\]</span></span></p>
<p>Die Residuen werden minimmiert, wenn die Summe der quadrierten Residuen (auch Error) minimiert werden, also die Summe <span class="math inline">\(sum_{i=1}^n e_i^2\)</span> möglichst klein ist. Für die Summe der quadrierten Fehler (Sum of Squared Errors: SSE) können wir schreiben:</p>
<p><span id="eq-2.5"><span class="math display">\[
\sum_{i=1}^n e_i^2=\sum_{i=1}^n\left(Y_i-\hat{Y}_i\right)^2=\sum_{i=1}^n\left(Y_i-b_1-b_2 X_2-b_3 X_{i 3}\right)^2
\tag{2.2}\]</span></span></p>
<p>Wenn wir die Summe der quadrierten Fehler (SSE) minimieren wollen, leiten wir die SSE nach den gesuchten b ab (das <span class="math inline">\(\partial\)</span> steht für differenzieren, also ableiten; das <span class="math inline">\(\partial b\)</span> unter dem Bruchstrich bedeutet, dass nach b abgeleitet wird und nicht etwa, dass irgendwie durch b geteilt wird): <span id="eq-2.6"><span class="math display">\[
\frac{\partial S S E}{\partial b}=\frac{\partial\left(\sum_{i=1}^n e_i^2\right)}{\partial b}=\frac{\partial\left(e_1^2\right)}{\partial b}+\frac{\partial\left(e_2^2\right)}{\partial b}+\cdots+\frac{\partial\left(e_i^2\right)}{\partial b}=\sum_{i=1}^n \frac{\partial\left(e_i^2\right)}{\partial b}
\tag{2.3}\]</span></span></p>
<p>Nach den Ableitungsregeln kann man die Ableitung einer Summe zerlegen in die Ableitung der einzelnen Summanden. Das steht in <a href="#eq-2.6">Gleichung&nbsp;<span>2.3</span></a>. Nach den ableitungsregeln kann man daraus Folgendes machen (schauen Sie nur darauf, wonach jeweils abgeleitet wird. Alle anderen Teile fallen weg. In <a href="#eq-2.4">Gleichung&nbsp;<span>2.1</span></a> wird zB nach <span class="math inline">\(b_1\)</span> abgeleitet, und die Ableitung einer Konstanten (<span class="math inline">\(b_1\)</span>) ist 1 und mit dem Minuszeichen davor, bleibt eben -1 übrig. In <a href="#eq-2.6">Gleichung&nbsp;<span>2.3</span></a> wird nach <span class="math inline">\(b_2\)</span> abgeleitet. Darum bleibt aus der Formel <span class="math inline">\(b_2X_{i 3}\)</span> übrig, was nach Ableitungsregeln <span class="math inline">\(X_{i 2}\)</span> entspricht und wieder mit einem Minuszeichen aus der Formel versehen ist.):</p>
<p><span id="eq-2.7"><span class="math display">\[
\frac{\partial\left(e_i^2\right)}{\partial b}=\frac{\partial\left(e_i^2\right)}{\partial e_i} \frac{\partial e_i}{\partial b}=2 e_i \frac{\partial e_i}{\partial b}
\tag{2.4}\]</span></span></p>
<p>und nach Gleichung <a href="#eq-2.4">Gleichung&nbsp;<span>2.1</span></a>, <span id="eq-2.8"><span class="math display">\[
\begin{gathered}
\frac{\partial e_i}{\partial b_1}=\frac{\partial\left(Y_i-b_1-b_2 X_{i 2}-b_3 X_{i 3}\right)}{\partial b_1}=-1,
\end{gathered}
\tag{2.5}\]</span></span></p>
<p><span id="eq-2.9"><span class="math display">\[
\begin{gathered}
\frac{\partial e_i}{\partial b_2}=\frac{\partial\left(Y_i-b_1-b_2 X_{i 2}-b_3 X_{i 3}\right)}{\partial b_2}=-X_{i 2},
\end{gathered}
\tag{2.6}\]</span></span></p>
<p><span id="eq-2.10"><span class="math display">\[
\begin{gathered}
\frac{\partial e_i}{\partial b_3}=\frac{\partial\left(Y_i-b_1-b_2 X_{i 2}-b_3 X_{i 3}\right)}{\partial b_3}=-X_{i 3} .
\end{gathered}
\tag{2.7}\]</span></span></p>
<p>Jetzt müssen alle Formeln von <a href="#eq-2.8">Gleichung&nbsp;<span>2.5</span></a> bis <a href="#eq-2.10">Gleichung&nbsp;<span>2.7</span></a> zusammengefügt und die einzelnen Ableitungen gleich 0 gesetzt werden, um die Gesamtfunktion zu minimieren: <span class="math display">\[
\begin{aligned}
\frac{\partial S S E}{\partial b_1} &amp; =2 \sum_{i=1}^n e_i \frac{\partial e_i}{\partial b_1}=2 \sum_{i=1}^n\left(Y_i-b_1-b_2 X_{i 2}-b_3 X_{i 3}\right)(-1) \\
&amp; =-2 \sum_i Y_i+2 \sum_i b_1+2 b_2 \sum_i X_{i 2}+2 b_3 \sum_i X_{i 3}
\end{aligned}
\]</span></p>
<p>dafür können wir schreiben: <span id="eq-2.11"><span class="math display">\[
-\sum_i Y_i+n b_1+b_2 \sum_i X_{i 2}+b_3 \sum_i X_{13}=0
\tag{2.8}\]</span></span></p>
<p>Jetzt wollen wir die SSE noch für bzw. nach <span class="math inline">\(b_2\)</span> ableiten: <span class="math display">\[
\frac{\partial S S E}{\partial b_2}=2 \sum_{i=1}^n e_i \frac{\partial e_i}{\partial b_2}=2 \sum_{i=1}^n\left(Y_i-b_1-b_2 X_{i 2}-b_3 X_{i 3}\right)\left(-X_{i 2}\right)
\]</span></p>
<p>oder nach der Zerlegung der Summe in die einzelnen Summanden, die jeweils mit <span class="math inline">\(-X_{i 2}\)</span> multipliziert wird und sich darum immer das Vorzeichen umkehrt.</p>
<p><span id="eq-2.12"><span class="math display">\[
-\sum_i Y_i X_{i 2}+b_1 \sum_i X_{i 2}+b_2 \sum_i X_{i 2}^2+b_3 \sum_i X_{i 3} X_{i 2}=0
\tag{2.9}\]</span></span></p>
<p>Nun fehlt nur noch die Ableitung der SSE nach <span class="math inline">\(b_2\)</span>: <span class="math display">\[
\frac{\partial S S E}{\partial b_3}=2 \sum_{i=1}^n e_i \frac{\partial e_i}{\partial b_3}=2 \sum_{i=1}^n\left(Y_i-b_1-b_2 X_{i 2}-b_3 X_{i 3}\right)\left(-X_{i 3}\right)
\]</span></p>
<p>und wie bei <span class="math inline">\(b_2\)</span>: <span id="eq-2.13"><span class="math display">\[-
\begin{gathered}
-\sum_i Y_i X_{i 3}+b_1 \sum_i X_{i 3}+b_2 \sum_i X_{i 2} X_{i 3}+b_3 \sum_i X_{i 3}^2=0 .
\end{gathered}
\tag{2.10}\]</span></span></p>
<p>Jetzt teilen wir jeweils die <a href="#eq-2.11">Gleichung&nbsp;<span>2.8</span></a> bis <a href="#eq-2.13">Gleichung&nbsp;<span>2.10</span></a> durch die Fallzahl, also <span class="math inline">\(n\)</span>, woraus sich ergibt (etwas konventionaller geschrieben und erstmal übersichtlicher):</p>
<p><span class="math display">\[
\begin{aligned}
b_1+a_1 b_2+a_2 b_3 &amp; =c_1, \\
a_1 b_1+a_3 b_2+a_4 b_3 &amp; =c_2, \\
a_2 b_1+a_4 b_2+a_3 b_3 &amp; =c_3,
\end{aligned}
\]</span></p>
<p>wobei sich hinter den a’s und c’s folgende Elemente verbergen, die am Ende eigentlich immer recht einfach (<span class="math inline">\(\bar{X}_2\)</span> und so) ausfallen:</p>
<p><span id="eq-2.13b"><span class="math display">\[
\begin{gathered}
a_1=\frac{1}{n} \sum X_{i 2}=\bar{X}_2, \quad a_2=\frac{1}{n} \sum X_{i 3}=\bar{X}_3, \quad a_3=\frac{1}{n} \sum X_{i 2}^2, \\
a_4=\frac{1}{n} \sum X_{i 2} X_{i 3}, \quad a_5=\frac{1}{n} \sum X_{i 3}^2, \\
c_1=\frac{1}{n} \sum Y_i=\bar{Y}, \quad c_2=\frac{1}{n} \sum Y_i X_{i 2}, \quad c_3=\frac{1}{n} \sum Y_i X_{i 3} .
\end{gathered}
\tag{2.11}\]</span></span></p>
<p>Durch Einsetzten erhalten wir also: <span id="eq-2.14"><span class="math display">\[
\bar{Y}=b_1+b_2 \bar{X}_2+b_3 \bar{X}_3 \quad \text { umgestellt } \quad b_1=\bar{Y}-b_2 \bar{X}_2-b_3 \bar{X}_3
\tag{2.12}\]</span></span></p>
<p>und <a href="#eq-2.12">Gleichung&nbsp;<span>2.9</span></a> sowie <a href="#eq-2.13">Gleichung&nbsp;<span>2.10</span></a> sind</p>
<p><span id="eq-2.12_2.13b"><span class="math display">\[
\begin{aligned}
&amp; \bar{X}_2 b_1+\left(\frac{1}{n} \sum X_{i 2}^2\right) b_2+\left(\frac{1}{n} \sum X_{i 2} X_{i 3}\right) b_3=\frac{1}{n} \sum Y_i X_{i 2} \\
&amp; \bar{X}_3 b_1+\left(\frac{1}{n} \sum X_{i 2} X_{i 3}\right) b_2+\left(\frac{1}{n} \sum X_{i 3}^2\right) b_3=\frac{1}{n} \sum Y_i X_{i 3} .
\end{aligned}
\tag{2.13}\]</span></span></p>
<p>Wenn man jetzt das <span class="math inline">\(b_1\)</span> aus <a href="#eq-2.14">Gleichung&nbsp;<span>2.12</span></a> einsetzt, ergibt sich <span id="eq-2.13n1"><span class="math display">\[
\begin{aligned}
&amp; b_2\left(\frac{1}{n} \sum X_{i 2}^2-\bar{X}_2^2\right)+b_3\left(\frac{1}{n} \sum X_{i 2} X_{i 3}-\bar{X}_2 \bar{X}_3\right)=\left(\frac{1}{n} \sum Y_i X_{i 2}-\bar{Y} \bar{X}_2\right) \\
&amp; b_2\left(\frac{1}{n} \sum X_{i 2} X_{i 3}-\bar{X}_2 \bar{X}_3\right)+b_3\left(\frac{1}{n} \sum X_{i 3}^2-\bar{X}_3^2\right)=\left(\frac{1}{n} \sum Y_i X_{i 3}-\bar{Y} \bar{X}_3\right)
\end{aligned}
\tag{2.14}\]</span></span></p>
<p>Die Varianzen der Variable X ist <span class="math inline">\(\left[V_X=(1 / n) \sum X_i^2-\bar{X}^2\right]\)</span> und die Kovarianz von <span class="math inline">\(X\)</span> und <span class="math inline">\(Y\)</span> ist <span class="math inline">\(\left[C_{X Y}=(1 / n) \sum X_1 Y_i-\bar{X} \bar{Y}\right]\)</span>, also kann man für die <a href="#eq-2.13n1">Gleichung&nbsp;<span>2.14</span></a> etwas übersichtlicher schreiben: <span class="math display">\[
b_2 V_{X_2}+b_3 C_{X_2 X_3}=C_{Y X_2}, \quad b_2 C_{X_2 X_3}+b_3 V_{X_3}=C_{Y X_3}
\]</span></p>
<p>Das ist damit auch das Ergebnis der ganzen Ableitung: Die b’s lassen sich aus den Varianzen und Kovarianzen der Variablen bestimmen!</p>
<p>Um eine noch übersichtlichere Schreibweise zu bekommen, lassen wir jetzt noch die Subscripte der ganzen X weg. Also schreiben wir ddie Varianzt von <span class="math inline">\(X_2\)</span> nicht mehr als <span class="math inline">\(V_{X_2}\)</span>, sondern einfach als <span class="math inline">\(V_2\)</span> und die Kovarianz zwischen <span class="math inline">\(X_2\)</span> und <span class="math inline">\(X_3\)</span> statt <span class="math inline">\(C_{X_2 X_3}\)</span> als <span class="math inline">\(C_{2 3}\)</span>. Dann vereinfacht sich das Ganze für <span class="math inline">\(b_2\)</span> zu:</p>
<p><span id="eq-2.15"><span class="math display">\[
\begin{aligned}
b_2=\left(V_3 C_{Y 2}-C_{23} C_{Y 3}\right) /\left(V_2 V_3-C_{23}^2\right) .
\end{aligned}
\tag{2.15}\]</span></span></p>
<p>und für <span class="math inline">\(b_3\)</span>:</p>
<p><span id="eq-2.16"><span class="math display">\[
\begin{aligned}
&amp; b_3=\left(V_2 C_{Y 3}-C_{23} C_{Y 2}\right) /\left(V_2 V_3-C_{23}^2\right) .
\end{aligned}
\tag{2.16}\]</span></span></p>
<p>Und weil die Korrelelation <span class="math inline">\(r_{Y 2} = C_{Y 2} / S_2S_Y\)</span> ist und die Varianz <span class="math inline">\(V = S^2\)</span>, kann man für die <a href="#eq-2.15">Gleichung&nbsp;<span>2.15</span></a> kann man, statt der Covarianzen und Varianzen, Korrelationen schreiben:</p>
<p><span id="eq-2.15s"><span class="math display">\[
b_2 = \frac{\left(V_3 C_{Y 2}-C_{23} C_{Y 3}\right)}{\left(V_2 V_3-C_{23}^2\right)}=\frac{r_{Y 2}-r_{23} r_{Y 3}}{\left(1-r_{23}^2\right)} \frac{S_Y}{S_2} .
\tag{2.17}\]</span></span> (Wer Lust hat, zeigt, dass das die <a href="#eq-2.15s">Gleichung&nbsp;<span>2.17</span></a> stimmt.)</p>
</div>
</div>
</div>
<hr>
<p>Ich habe Ihnen eine Excel-Datei gebaut, mit der Sie sich das Prinzip von OLS interaktiv anschauen können:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://www.ikmz.uzh.ch/static/methoden/Statistik-Aufbau/files/OLS.xlsx"><img src="images/OLS_xlsx.jpg" title="Link zu OLS-xlsx" class="img-fluid figure-img" style="width:100.0%"></a></p>
<p></p><figcaption class="figure-caption">OLS-xlsx</figcaption><p></p>
</figure>
</div>
<hr>
<hr>
<p><strong>Welche Funktion und Eigenschaften hat OLS</strong></p>
<div class="cell" data-hash="02_GLM_cache/html/unnamed-chunk-4_d7c930e4ce1dd1a2fbcd34cf39adfb05">

</div>
<div id="radio_ULBFDPBCYV" class="webex-radiogroup">
<label><input type="radio" autocomplete="off" name="radio_ULBFDPBCYV" value="answer"> <span>Mit OLS kann die Grösse der b's bestimmt werden.</span></label><label><input type="radio" autocomplete="off" name="radio_ULBFDPBCYV" value=""> <span>OLS ist voraussetzungslos</span></label><label><input type="radio" autocomplete="off" name="radio_ULBFDPBCYV" value="answer"> <span>Es gibt noch andere Optimierungsverfahren zur Bestimmung von b's. </span></label><label><input type="radio" autocomplete="off" name="radio_ULBFDPBCYV" value=""> <span>OLS ist das englische Akronym für <strong>O</strong>nly <strong>L</strong>inear <strong>S</strong>ystems</span></label>
</div>
<hr>
</section>
<section id="bs" class="level3" data-number="2.2.3">
<h3 data-number="2.2.3" class="anchored" data-anchor-id="bs"><span class="header-section-number">2.2.3</span> B’s</h3>
<p>Wenn wir mit Hilfe der OLS-Methode eine Formel für die b’s gesucht haben, kommt folgende Formel @ref(eq:FormelFuerBs) für das <span class="math inline">\(b_2\)</span> der Variable <span class="math inline">\(x_2\)</span> heraus :</p>
<span class="math display">\[\begin{align}
b_2 = \frac{r_{y2}-r_{23}r_{y3}}{(1-r_{23}^2)}\frac{s_y}{s_2} \label{eq:FormelFuerBs}
\end{align}\]</span>
<p>Die Formel hat es in sich. Aber schauen Sie sich die Formel mal ganz in Ruhe und stückchenweise an. Als eines der ersten Elemente taucht <span class="math inline">\(r_{y2}\)</span> auf, was so viel heisst, wie die einfache Korrelation zwischen y und der ersten x-Variable, die ja das <span class="math inline">\(b_2\)</span> hat und darum kurz und knapp nur noch mit dem Subscript 2 bedacht wird. Also hängt das b mit der Korrelation zwischen der zugehörigen x-Variable und y zusammen. Da b skalenabhängig ist und r nicht, steht hinten noch dieses <span class="math inline">\(\frac{S_y}{S_2}\)</span>. Dieser Termin sorgt nur dafür, dass b in der Skala von y angegeben ist (darum auch multipliziert mit <span class="math inline">\(s_y\)</span>) – den Teil können Sie schon mal vergessen. Interessanter ist der zweite Teil der Gleichung über dem Bruchstrich: Wir ziehen da das Produkt aus <span class="math inline">\(r_{23}\)</span> und <span class="math inline">\(r_{y3}\)</span> ab. Das heisst, wir gehen von der bivariaten Korrelation aus, rechnen jetzt aber noch die Korrelation raus, die die beiden unabhängigen Variablen <span class="math inline">\(x_2\)</span> und <span class="math inline">\(x_3\)</span> untereinander haben. Wir ziehen allerdings nicht einfach <span class="math inline">\(r_{23}\)</span> ab, sondern multiplizieren das auch noch mit <span class="math inline">\(r_{y3}\)</span>. Das bedeutet, wir haben einen Zusammenhang <span class="math inline">\(r_{y2}\)</span> und rechnen aus dem den Anteil gemeinsamer Varianz, also der Zusammenhänge der Varialbe <span class="math inline">\(x_2\)</span> heraus, die diese mit <span class="math inline">\(x_3\)</span>, wobei wir nur so viel rausrechnen, wie die dritte Variable <span class="math inline">\(x_3\)</span> wiederum mit y gemeinsam hat. Wären die beiden Variablen <span class="math inline">\(x_2\)</span> und <span class="math inline">\(x_3\)</span> unkorrelliert, dann wäre auch das Produkt <span class="math inline">\(r_{23}r_{y3} = 0\)</span>, weil <span class="math inline">\(0 \cdot r_{y3} = 0\)</span>. Wenn <span class="math inline">\(x_2\)</span> und <span class="math inline">\(x_3\)</span> korrellieren, aber <span class="math inline">\(x_3\)</span> und y nicht, dann würden wir auch nichts von <span class="math inline">\(r_{y2}\)</span> abziehen. Im Storchenbeispiel würden wir also sagen, wir sehen den Zusammenhang zwischen Geburtenrate und Anzahl Störche. Wir müssen aber aus dieser Korrelation herausrechnen, dass die Drittvariable (<span class="math inline">\(x_3\)</span>) Bevölkerungsdichte (Stadt vs.&nbsp;Land) stark mit der Geburtenrate korrelliert und mit der Anzahl der Störche, die in einer Region leben.</p>
</section>
<section id="das-bestimttheitsmass-r2" class="level3" data-number="2.2.4">
<h3 data-number="2.2.4" class="anchored" data-anchor-id="das-bestimttheitsmass-r2"><span class="header-section-number">2.2.4</span> Das Bestimttheitsmass <span class="math inline">\(R^2\)</span></h3>
<p>Das Bestimmtheitsmass gibt an, wie gut die Werte der AV durch die Werte der UV vorhergesagt werden können.</p>
<p>Wie viel von der Varianz der AV durch ein Modell aufgeklärt werden kann, stellt man fest, indem zunächst die Summe der quadrierten Abweichungen (<strong>S</strong>um of <strong>S</strong>quares) für alle <span class="math inline">\(Y_i\)</span> Werte gezählt werden. Also die totale Varianz der AV, die geschrieben wird als <span class="math inline">\(SS_T\)</span> (Sum of Squares Total). Jetzt ist die Frage, wie viel von dieser Sum of Squares Total durch die Sum of Squares des Modells (<span class="math inline">\(SS_M\)</span>) erklärt werden kann. Darum setzen wir diese beiden Summen der Quadrate (wenn man jeweils durch n teilen würde, wären das die Varianzen) ins Verhältnis zueinander und bekommen einen Prozentwert. Also rechnen wir <span class="math inline">\(\frac{SS_M}{SS_T}\)</span> und bekommen einen Wert zwischen 0 und 1 bzw. 0% und 100% (% heisst ja «von Hundert» bzw. «geteilt durch 100»). Das ist der aufgeklärte Varianzanteil und den nennen wir <span class="math inline">\(R^2\)</span>.</p>
<ul>
<li><span class="math inline">\(SS_T\)</span>: Summe der quadrierten Abweichungen für die AV (Y).</li>
<li><span class="math inline">\(SS_M\)</span>: Summe der quadrierten Abweichungen des Modells (der Punkte auf der Geraden, bzw. die geschätzten <span class="math inline">\(\hat{Y_i}\)</span>-Werte).</li>
</ul>
<p>Also: <span class="math inline">\(R^2 = \frac{SS_M}{SS_T}\)</span></p>
<p>Bei dieser Formel @ref(eq:Varianzaufklaerung) können wir durch n teilen, also über und unter dem Bruch <span class="math inline">\(1/n\)</span> ergänzen und hätten:</p>
<span class="math display">\[\begin{align}
R^2 = \frac{SS_M/n}{SS_/T} \label{eq:Varianzaufklaerung}
\end{align}\]</span>
<p>Was in Worten ausgedrückt bedeutet:</p>
<span class="math display">\[\begin{align}
R^2 = \frac{\text{aufgeklärte Varianz}}{\text{Gesamtvarianz}} \label{eq:Varianzaufklaerung-verbal}
\end{align}\]</span>
<div class="cell" data-hash="02_GLM_cache/html/R2_fec523cd115f4c7d91dbeb18a7662bc2">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/SumOfSquares.jpg" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">R-Quadrat</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Mit dem Bestimmtheitsmass können wir angeben, wie gut ein Modell insgesamt ist. Wir werden später noch diskutieren, wie sinnvoll das ist. Spoiler: Nicht immer sehr sinnvoll, weil <span class="math inline">\(R^2\)</span> eigentlich mehr eine Stichprobeneigenschaft ist und wenig über die Welt sagt und recht einfach hochgeschraubt werden kann, indem man triviale und langweilige Variablen in ein Modell einbaut.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
IYI: Ableitung für <span class="math inline">\(R^2\)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math display">\[
s^2=\frac{1}{n-3} \sum\left(e_i-\bar{e}\right)^2=\frac{1}{n-3} \sum e_i^2 .
\]</span> ar <span class="math inline">\(\bar{e}=0\)</span>.) The denominator <span class="math inline">\(n-3\)</span> reflects the fac and <span class="math inline">\(b_3\)</span> ) have been estimated; in the general cs tions minus the number of parameters estims alue of <span class="math inline">\(\sum e_i^2, s^2\)</span> can be shown to be an unbias</p>
<p><span class="math inline">\(s_{b_2}^2=\frac{s^2}{n} \frac{1 / V_2}{1-r_{23}^2} \quad\)</span> and <span class="math inline">\(\quad s_{b_3}^2=\frac{s^2}{n} \frac{1 / V_3}{1-r_{23}^2}\)</span> where <span class="math inline">\(s_{b_2}^2\)</span> and <span class="math inline">\(s_{b_3}^2\)</span> denote our estimates of the coefficients’ variance. Since <span class="math inline">\(E\left(s^2\right)=\sigma^2\)</span>, and the <span class="math inline">\(X^{\prime}\)</span> ‹s are fixed, this gives an unbiased estimate of the coefficients› variance. The estimated standard errors of the coefficients, symbolized as <span class="math inline">\(s_{b_2}\)</span> and <span class="math inline">\(s_{b_3}\)</span>, are simply the square root of these expressions. The information about the error variance-as estimated from the sum of squared residuals-supplies us with a description of the probability function that generated the errors in the true model. However, there are two transformations of <span class="math inline">\(s^2\)</span> that produce more easily interpreted statistics.</p>
<p>The first transformation is simply the square root of <span class="math inline">\(s^2\)</span>. This statistic <span class="math inline">\(s\)</span> is important enough to deserve its own name: the standard error of estimate. ’In the first place, <span class="math inline">\(s\)</span> is measured in the same units as <span class="math inline">\(Y\)</span> (whereas <span class="math inline">\(s^2\)</span> is in the units of <span class="math inline">\(Y\)</span> squared). The standard error of estimate is also useful because it gives some feel for the size of the dispersion when compared to tables for the normal distribution. For a normal distribution, we expect about <span class="math inline">\(95 \%\)</span> of all values to lie within plus or minus two standard deviations of the mean. Thus, if the <span class="math inline">\(U_i\)</span> are normally distributed (as we often assume), we can expect <span class="math inline">\(95 \%\)</span> of all actual values of <span class="math inline">\(Y_i\)</span> in our sample to be within plus or minus two standard errors of estimate away from the estimated line. <span class="math inline">\({ }^8\)</span> The estimate <span class="math inline">\(s\)</span> thus allows an easier interpretation of the magnitude of the error terms.</p>
<p>The second transformation of the error variance makes a comparison with the total amount of variance in behavior <span class="math inline">\(\operatorname{var}(Y)\)</span> existing in the sample. One may wish to compare how well an estimated model does when matched with a «naïve» guess at the behavior in question.</p>
<p>With no information about the underlying behavioral relationships, one guess of the value of any <span class="math inline">\(Y_i\)</span> is the mean value of all the observed <span class="math inline">\(Y^{\prime}\)</span> s. The variance of <span class="math inline">\(Y\)</span> is then the sum of squared deviations around this guess divided by the number of observations on the behavior. The sum of squared residuals <span class="math inline">\(\left(\sum e_i^2\right)\)</span> is a measure of how far our «sophisticated» guesses, represented by <span class="math inline">\(\hat{Y}_i=b_1+b_2 X_{i 2}+b_3 X_{i 3}\)</span>, diverge from the actual values of <span class="math inline">\(Y_i\)</span>. Thus, comparing the residual variance <span class="math inline">\(\left(\sum e_i^2 / n\right)\)</span> to the variance of <span class="math inline">\(Y\)</span> gives some indication of the overall performance of our model relative to the simpler «model.» If we look at <span class="math inline">\(\Sigma e_i^2 / \Sigma\left(Y_i-\bar{Y}\right)^2\)</span>, we see that this can range from zero when <span class="math inline">\(\Sigma e_i^2=0\)</span> to</p>
<p>a maximum value of one. (Why, according to the least squares procedure, can this ratio never exceed one?) By convention, we create a new statistic, defined as, <span class="math display">\[
R^2=1-\left[\sum e_i^2 / \sum\left(Y_i-\bar{Y}\right)^2\right] .
\]</span> This statistic, referred to simply as <span class="math inline">\(R\)</span>-squared (or as the coefficient of determination) has the following properties: (1) when all points fall on the estimated plane so that <span class="math inline">\(Y_i \equiv \hat{Y}_i, R^2\)</span> equals one (its maximum); (2) when the mean does as well at predicting <span class="math inline">\(Y_i\)</span> as the estimated equation, <span class="math inline">\(R^2\)</span> equals zero (its minimum); (3) between these two extremes, <span class="math inline">\(R^2\)</span> gives an ordinal measure of how well the model predicts the sample values of <span class="math inline">\(Y\)</span>.</p>
<p>Another way to look at <span class="math inline">\(R^2\)</span> is found by transforming <span class="math inline">\(\Sigma\left(Y_i-\bar{Y}\right)^2\)</span> as follows: <span class="math display">\[
\begin{aligned}
\sum\left(Y_i-\bar{Y}\right)^2 &amp; =\sum\left[\left(Y_i-\hat{Y}_i\right)+\left(\hat{Y}_i-\bar{Y}\right)\right]^2 \\
&amp; =\sum\left(Y_i-\hat{Y}_i\right)^2+\sum\left(\hat{Y}_i-\bar{Y}\right)^2+2 \sum\left(Y_i-\hat{Y}_i\right)\left(\hat{Y}_i-\bar{Y}\right) .
\end{aligned}
\]</span> Since <span class="math inline">\(Y_i-\hat{Y}_i=e_i\)</span> and <span class="math inline">\(\hat{Y}_i-\bar{Y}=b_2\left(X_{i 2}-\bar{X}_2\right)+b_3\left(X_{i 3}-\bar{X}_3\right)\)</span>, the last summation is simply equal to <span class="math inline">\(2 b_2 \Sigma\left(X_{i 2}-\bar{X}_2\right) e_i+2 b_3 \Sigma\left(X_{i 3}-\bar{X}_3\right) e_i\)</span>. However, by the arithmetic properties of least squares demonstrated above, this is identically zero. Thus <span class="math display">\[
\sum\left(Y_i-\bar{Y}\right)^2=\sum\left(Y_i-\hat{Y}\right)^2+\sum\left(\hat{Y}_i-\bar{Y}\right)^2=\sum e_i^2+\sum\left(\hat{Y}_i-\bar{Y}\right)^2
\]</span> This says that the variance of <span class="math inline">\(Y\)</span> can be divided into two components. The first <span class="math inline">\(\left(\Sigma e_i^2\right)\)</span> is the «unexplained» portion or the residual portion of the model. The second, called the «explained» portion, indicates how much better the estimated model does than using a fixed estimate of the mean would do. By rearranging (3.12), we see that <span class="math display">\[
R^2=\sum\left(\hat{Y}_i-\bar{Y}\right)^2 / \sum\left(Y_i-\bar{Y}\right)^2
\]</span> Thus, <span class="math inline">\(R^2\)</span> can be interpreted as the proportion of the variation in the sample <span class="math inline">\(Y_i\)</span> explained by the regression equation.</p>
<p>Finally, if one correlates the actual and predicted values of <span class="math inline">\(Y\)</span>, one arrives at the correlation coefficient <span class="math inline">\(R\)</span>. Squaring this yields the same value of <span class="math inline">\(R^2\)</span> as found in (3.12) and (3.14).</p>
</div>
</div>
</div>
<hr>
<p><strong>Was wissen Sie über das Bestimmtheitsmass</strong> <span class="math inline">\(R^2\)</span>?</p>
<div class="cell" data-hash="02_GLM_cache/html/unnamed-chunk-5_875d5173c945be303d81887ab682b1f3">

</div>
<div id="radio_KGUFIVJUBQ" class="webex-radiogroup">
<label><input type="radio" autocomplete="off" name="radio_KGUFIVJUBQ" value=""> <span><span class="math inline">\(R^2\)</span> ist die Gesamtvarianz geteilt durch die Modellvarianz.</span></label><label><input type="radio" autocomplete="off" name="radio_KGUFIVJUBQ" value=""> <span><span class="math inline">\(R^2\)</span> ist ein Zusammenhangsmass und wird für jede UV angegeben.</span></label><label><input type="radio" autocomplete="off" name="radio_KGUFIVJUBQ" value="answer"> <span><span class="math inline">\(R^2\)</span> ist ein Mass für die Modellgüte.</span></label><label><input type="radio" autocomplete="off" name="radio_KGUFIVJUBQ" value="answer"> <span><span class="math inline">\(R^2\)</span> liegt immer zwischen 0 und 1</span></label>
</div>
<hr>
</section>
<section id="kennwerte-der-regression" class="level3" data-number="2.2.5">
<h3 data-number="2.2.5" class="anchored" data-anchor-id="kennwerte-der-regression"><span class="header-section-number">2.2.5</span> Kennwerte der Regression</h3>
<div class="cell" data-hash="02_GLM_cache/html/KennwerteModell_a8e75ab3945d845ccf476dd9eca906c1">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Kennwerte_Modellguete.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Kennwerte auf Modellgüte</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-hash="02_GLM_cache/html/KennwerteVar_b1410817627e9562896eee625326103b">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Kennwerte_Variablenebene.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Kennwerte auf Variablenebene</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-hash="02_GLM_cache/html/KennwerteSignifikanz_06861f6696c641f3de47f6ac75eda930">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Kennwerte_Signifikanz.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Kennwerte der Signifikanz der b’s</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-hash="02_GLM_cache/html/KennwerteMultikollinearität_b9fa6ec1f3adb99fc6eb90db70486d25">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Kennwerte_Multikollinearitaet.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Kennwerte der Multikollinearität</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="vorraussetzung-für-blue" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="vorraussetzung-für-blue"><span class="header-section-number">2.3</span> Vorraussetzung für BLUE</h2>
<p>Damit unsere b’s aus der OLS die besten linearen unverzerrten Schätzer (BLUE:<strong>B</strong>est <strong>L</strong>inear <strong>U</strong>nbiased <strong>E</strong>stimator) für die <span class="math inline">\(\beta\)</span>s sind, müssen ein paar Voraussetzungen erfüllt sein. Diese Voraussetzungen gucken wir uns in diesem Kapitel an. Zusammengefasst sind es:</p>
<p>V1. Die UVs und die AV dürfen keine Konstanten sein.</p>
<p>V2. Das Skalenniveau der UVs muss metrisch oder dichotom (0/1) sein.</p>
<p>V3. Die Werte der X müssen fix sein.</p>
<p>V4. Das Modell muss voll spezifiziert sein. D.h.: Keine Korrelation mit externen Variablen.</p>
<p>V5. Es darf keine <strong>perfekte</strong> oder <strong>heftige</strong> Multikollinearität geben.</p>
<p>V6. Die Residuen müssen bei jedem Wert jeder UV gleich streuen (Homoskedastizität).</p>
<p>V7. Die Residuen müssen grob normalverteilt sein.</p>
<p>V8. Die Residuen dürfen nicht autokorreliert sein.</p>
<hr>
<p><strong>Was verbirgt sich hinter demm Akronym BLUE (ausgeschrieben)?</strong></p>
<div class="webex-solution">
<button>
Lösung anschauen
</button>
<p><strong>B</strong>est <strong>L</strong>inear <strong>U</strong>nbiased <strong>E</strong>stimator</p>
</div>
<hr>
<section id="variablenskalierung-v1.-v2." class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="variablenskalierung-v1.-v2."><span class="header-section-number">2.3.1</span> Variablenskalierung (V1.-V2.)</h3>
<p>Die beiden ersten Voraussetzungen (V1. und V2.) betreffen die Skalierung der Variablen.</p>
<section id="sec:V1" class="level4" data-number="2.3.1.1">
<h4 data-number="2.3.1.1" class="anchored" data-anchor-id="sec:V1"><span class="header-section-number">2.3.1.1</span> Variablen dürfen keine Konstanten sein (V1.)</h4>
<p>Die UVs und die AV dürfen keine Konstante sein. Das ist insofern recht trivial, als dass eine Konstante mit nichts kovariieren kann, weil Konstanten nicht variieren. Je grösser «<span class="math inline">\(\pi\)</span>, desto <span class="math inline">\(...\)</span>» macht einfach keinen Sinn. Da Konstanten nicht variieren (keine Varianz haben), können sie nicht kovariieren und können daher in keinen Erklärungsmodellen als Variablen einbezogen werden. An dieser Stelle klingt das sehr trivial. Und doch kommt es immer wieder vor, dass in Hypothesen Variablen einfliessen, die in der gewählten Stichprobe konstant sind. Zum Beispiel ist in der Hypothese «Wenn über Sport berichtet wird, zählen Superlative besonders.» Das Konstrukt «über Sport berichtet» ist eine Konstante, wenn nur der Sportteil untersucht werden soll. Hypothesen sind keine Annahmen über Zusammenhänge mehr, wenn eines der Konstrukte, die in Hypothesen zusammengebracht werden, in den Daten eine Konstante ist. Oftmals kommen solche Hypothesen mit Konstanten zustande, wenn der Fokus auf eine Ausprägung einer Variablen gelegt wird und die Abweichung von dieser Ausprägung nicht erhoben wird. Annahmen über den Wandel von Kriegsberichterstattung kann als zeitlicher Prozess nicht untersucht werden, wenn nur das Heute untersucht wird. Oft genug kommen Konstanten in Hypothesen vor, wenn das Forschungsinteresse aus dem Interesse der Forschenden eigentlich deskriptiv ist, also nur die Verteilung von einzelnen Variablen gefragt ist, und dann posthoc Hypothesen formuliert werden sollen, weil das von den Dozierenden oder Reviewern verlangt bzw. erwartet wird. ;-)</p>
</section>
<section id="variablen-sollen-metrisch-sein-v2." class="level4" data-number="2.3.1.2">
<h4 data-number="2.3.1.2" class="anchored" data-anchor-id="variablen-sollen-metrisch-sein-v2."><span class="header-section-number">2.3.1.2</span> Variablen sollen metrisch sein (V2.)</h4>
<p>Die AV und die UVs sollen metrisch sein. Das klingt nach einer recht harten Voraussetzung. Allerdings gibt es die schöne Eigenschaft von Dummyvariablen (0/1), dass sie sich verhalten wie metrische Variablen, weil ihr Mittelwert und ihre Streuung sinnvoll interpretierbar sind. Dummyvariablen können also gut als UVs eingesetzt werden. Nun ist diese spezielle Form der dichotomen Variable (zwei Ausprägungen) nur die eine Form der nominalen Variablen. Dichotome Variablen können immer als Dummyvariable dargestellt werden. Man muss ja nur eine Ausprägung in 0 umkodieren und die andere in 1. Bei den kategorialen Variablen gibt es mehr Ausprägungen. Zum Beispiel Gender mit 1 = weiblich, 2 = männlich, 3 = divers<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Das Gute wiederum ist, dass kategoriale Variablen vollständig mit Dummyvariablen abgebildet werden können. Das geht dann so: Man baut eine Variable «Weiblich», die die Ausprägungen 1 = «trifft zu» und 0 = «trifft nicht zu» hat. Dann gibt es eine zweite Variable für «männlich» mit 0 und 1 und auch eine Dummy für «Divers». Diesem Vorgehen sind eigentlich keine Grenzen gesetzt. Man könnte also auch noch erweitern oder differenzieren in «transgender», «genderqueer», «genderfluid», «bigender», «pangender», «trigender», «agender», «demigender», «abinär» und zur Sicherheit in Deutschland auch «Taucher»<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
<p>In den linearen Modellen können Sie also auch kategoriale Variablen einbauen<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. Auch die AV kann eine Dummyvariable sein. Das führt allerdings zu ein paar Problemen mit dem einfachen linearen Modell. Deshalb werden bei einer AV mit nur den Ausprägungen 0 und 1 logistische Regressionen gerechnet. Damit befassen wir uns später. Es geht auch, dass die AV kategorial ist. Das ist dann so ähnlich wie mit den Dummys als UV, weil dann mehrere Regressionen mit mehreren Dummys für die AV gerechnet werden. Das wird multinominale Regression genannt (auch bekannt als Diskriminanzanalyse).</p>
<p>Dann bleiben im Grunde nur die ordinalen Variablen übrig, die mehr Informationen über Ordnung der Ausprägungen (Rangordnung) enthalten, aber die Zahlenwerte (numerisches Relativ) mit ihren identischen Abständen (1 zu 2 wie 2 zu 3 und 3 zu 4 usw.) nicht abbilden, dass die Abstände der gemessenen Ausrägungen (empirisches Relativ) nicht annähernd gleich sind (1 = «arm», zwei = «reich», 3 gleich «superreich»). Dafür gibt es drei Lösungen, um ordinale Variablen auch in lineare Modelle einbeziehen zu können.</p>
<ol type="1">
<li><p>Ordinale Variablen werden als metrisch oder quasimetrisch behandelt und wie metrische in ein Modell aufgenommen. Das geschieht praktisch häufig, wenn z.B. Schulnoten einfach in ein lineares Modell aufgenommen werden. Wir wissen, dass die Abstände zwischen der Schweizer Bestnote 6.0 und 5.5 nicht genauso gross sind, wie zwischen 5.5 und 5.0 oder gar 4.0 und 3.5. Dennoch sind die Schätzer der linearen Modelle relativ robust gegen diese Verletzung. Gerade wenn es eigentlich nur darum geht, zu prüfen, ob Schulnoten einen signifikanten Effekt auf eine AV haben, dann kann man diese ordinalen Variablen getrost als «quasimetrisch» verwenden. In diesen Fällen sollte man nur etwas vorsichtiger sein, wenn eine Signifikanzschwelle nur knapp gerissen wurde oder b als Effekt nur knapp die Schwelle der Interpretierbarkeit übersprungen hat, dann sollte man bescheiden sein und klar machen, dass aufgrund der Datenlage und dem Skalennivau der Variablen die Zahlen nicht überinterpretiert werden sollten.</p></li>
<li><p>Es gibt auch die Möglichkeit, ordinale Variablen als kategoriale Variablen zu behandeln (womit ihr Datenniveau aber eigentlich herabgestuft wird). Dann würden wir die Ausprägungen der ordinalen UVs wiederum in Dummyvariablen umkodieren und nur die Dummys interpretieren. Im besten Fall werden in solche Interpretationen die zugrundeliegende Rangfolge der Dummys berücksichtigt, also die erste Gruppe mit der zweiten, die zweite mit der Dritten und dann die erste mit der Dritten, aber mit Rücksicht auf die Bedeutung der Rangfolge.</p></li>
<li><p>Wenn eine oder mehrere UVs klar ordinal sind, also die Abstände zwischen den Zahlenwerte deutlich auseinandergehen oder vielleicht sogar variieren (Laufwettkampf mit mal sehr knappen Unterschieden und mal sehr grossen von Platz eins zu Platz zwei, wenn Kipchoge mitläuft), dann sollten die ordinalen nicht einfach als metrische betrachtet werden. Wenn solche ordinalen Variablen zentral sind, dann kann auch nicht einfach auf Dummys ausgewichen werden. Dafür gibt es aber inzwischen Analysemethoden der ordinalen Regression, die in diesen Fällen eingesetzt werden können. Mit dem Verständnis der normalen linearen Modelle ist es nicht mehr schwer, sich so gut selbständig in die ordinale Regression einzuarbeiten, dass sie gewinnbringend eingesetzt werden kann.</p></li>
</ol>
</section>
</section>
<section id="modellspezifikation-und-multikollinearität-v3.-v5." class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="modellspezifikation-und-multikollinearität-v3.-v5."><span class="header-section-number">2.3.2</span> Modellspezifikation und Multikollinearität (V3.-V5.)</h3>
<section id="v3.-fixe-x" class="level4" data-number="2.3.2.1">
<h4 data-number="2.3.2.1" class="anchored" data-anchor-id="v3.-fixe-x"><span class="header-section-number">2.3.2.1</span> V3. Fixe X</h4>
<p>Dass die UVs fix sein sollen, bedeutet im Grunde nur, dass sich die UVs nicht ständig ändern sollen, sondern in unserer Auswahlgesamtheit stabil sind. Wenn sich zum Beispiel die Berichterstattung insgesamt häufig stark ändert, dann wäre es nicht gut, wenn wir mit der Stichprobe einer Inhaltsanalyse arbeiten, die in einer sehr speziellen Zeit erhoben wurde (z.B. ein Kriegsanfang). Diese Stichprobe in einer Spezialzeit würde zu verzerrt geschätzten B’s in der Normalzeit führen <span class="citation" data-cites="Wolling2015">[vgl. @Wolling2015]</span>. Da wir nicht davon ausgehen können und wollen, dass unsere Theorien in der Sozialwissenschaft immer und ewig gelten, verlangen wir nur mittelfristig gültige Theorien («middle range theory» <span class="citation" data-cites="Merton2012">[@Merton2012]</span>) und dass unsere Variablen mittelfristig relativ stabil bzw. fix sind. Das bedeutet insbesondere, dass wir bei der Stichprobenziehung aufpassen müssen, dass wir nicht eine sehr spezielle Stichprobe in einer ganz besonderen Phase erheben, die Effekte hat, die sonst sehr untypisch sind. Das ist das, was mit fixe X gemeint ist.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
IYI: Fixe X in Formeln abgeleitet
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{aligned}
b_2 &amp; =\frac{V_3 C_{2 Y}-C_{23} C_{3 Y}}{D} \\
&amp; =\frac{(1 / n) \sum_{i=1}^n\left\{\left[V_3\left(X_{i 2}-\bar{X}_2\right)-C_{23}\left(X_{i 3}-\bar{X}_3\right)\right]\left(Y_i-\bar{Y}\right)\right\}}{D}
\end{aligned}
\]</span> where <span class="math inline">\(D=V_2 V_3-C_{23}^2\)</span>. From the true model for <span class="math inline">\(Y\)</span> and from averaging the <span class="math inline">\(Y_i\)</span> over the sample, we know that <span class="math display">\[
\begin{aligned}
Y_i-\bar{Y} &amp; =\beta_1+\beta_2 X_{i 2}+\beta_3 X_{i 3}+U_i-\left(\beta_1+\beta_2 \bar{X}_2+\beta_3 \bar{X}_3+\bar{U}\right) \\
&amp; =\beta_2\left(X_{i 2}-\bar{X}_2\right)+\beta_3\left(X_{i 3}-\bar{X}_3\right)+\left(U_i-\bar{U}\right)
\end{aligned}
\]</span> where <span class="math inline">\(\bar{U}\)</span> is the mean of all error terms implicit in the sample. By substitution, we have <span class="math display">\[
\begin{aligned}
&amp; b_2=\frac{1}{N D}\left\{\sum_{i=1}^n\left[V_3\left(X_{i 2}-\bar{X}_2\right)-C_{23}\left(X_{i 3}-\bar{X}_3\right)\right]\right. \\
&amp;\left.\times\left[\beta_2\left(X_{i 2}-\bar{X}_2\right)+\beta_3\left(X_{i 3}-\bar{X}_3\right)+\left(U_i-\bar{U}\right)\right]\right\} \\
&amp;=\frac{1}{D}\left\{\frac{\beta_2}{N} V_3 \sum\left(X_{i 2}-\bar{X}_2\right)^2-\frac{\beta_2}{N} C_{23} \sum\left(X_{i 3}-\bar{X}_3\right)\left(X_{i 2}-\bar{X}_2\right)\right. \\
&amp;+\frac{\beta_3}{N} V_3 \sum\left(X_{i 2}-\bar{X}_2\right)\left(X_{i 3}-\bar{X}_3\right)-\frac{\beta_3}{N} C_{23} \sum\left(X_{i 3}-\bar{X}_3\right)^2 \\
&amp;\left.+\frac{1}{N} \sum\left[V_3\left(X_{i 2}-\bar{X}_2\right)-C_{23}\left(X_{i 3}-\bar{X}_3\right)\right]\left(U_i-\bar{U}\right)\right\}
\end{aligned}
\]</span> The first summation can be written as <span class="math inline">\(\beta_2 V_3(1 / N) \Sigma\left(X_{i 2}-\bar{X}_2\right)^2=\beta_2 V_3 V_2\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
&amp; E\left(C_{2 U}\right)=\frac{1}{N} \sum\left(X_{i 2}-\bar{X}_2\right) E\left(U_i-\bar{U}\right)=\frac{1}{N} \sum\left(X_{i 2}-\bar{X}_2\right)\left(\bar{U}_i-\mu\right)=C_{2 \bar{U}_i} \\
&amp; E\left(C_{3 U}\right)=\frac{1}{N} \sum\left(X_{i 3}-\bar{X}_3\right) E\left(U_i-\bar{U}\right)=\frac{1}{N} \sum\left(X_{i 3}-\bar{X}_3\right)\left(\bar{U}_i-\mu\right)=C_3 \bar{U}_i,
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
b_1 &amp; =\bar{Y}-b_2 \bar{X}_2-b_3 \bar{X}_3=\beta_1+\beta_2 \bar{X}_2+\beta_3 \bar{X}_3+\bar{U}=b_2 \bar{X}_2-b_3 \bar{X}_3 \\
&amp; =\beta_1+\left(\beta_2-b_2\right) \bar{X}_2+\left(\beta_3-b_3\right) \bar{X}_3+\bar{U}_1
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
b_2 &amp; =\frac{\beta_2 V_3 V_2-\beta_2 C_{23}^2+\beta_3 V_3 C_{23}-\beta_3 C_{23} V_3}{D}+\frac{V_3 C_{2 U}-C_{23} C_{3 U}}{D} \\
&amp; =\frac{\beta_2\left(V_2 V_3-C_{23}^2\right)}{D}+\frac{V_3 C_{2 U}-C_{23} C_{3 U}}{D}=\beta_2+\frac{V_3 C_{2 U}-C_{23} C_{3 U}}{D} .
\end{aligned}
\]</span> Similar treatment of Eq. (2.16) gives <span class="math display">\[
b_3=\beta_3+\frac{V_2 C_{3 U}-C_{23} C_{2 U}}{D} \text {. }
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
&amp; E\left(b_2\right)=E\left(\beta_2\right)+E\left[\frac{V_3 C_{2 U}-C_{23} C_{3 U}}{D}\right] \\
&amp; E\left(b_3\right)=E\left(\beta_3\right)+E\left[\frac{V_2 C_{3 U}-C_{23} C_{2 U}}{D}\right] .
\end{aligned}
\]</span> <span class="math inline">\(\beta_2\)</span> and <span class="math inline">\(\beta_3\)</span> are constants, so <span class="math inline">\(E\left(\beta_2\right)=\beta_2\)</span> and <span class="math inline">\(E\left(\beta_3\right)=\beta_3\)</span>. Since we treat the values for the <span class="math inline">\(X\)</span> ’s as nonstochastic, or as fixed during all replicated experiments, <span class="math inline">\(V_2, V_3, C_{23}\)</span>, and <span class="math inline">\(D\)</span> can be treated as constants in taking expected values. Thus <span class="math display">\[
\begin{aligned}
&amp; E\left(b_2\right)=\beta_2+\frac{V_3 E\left(C_{2 U}\right)}{D}-\frac{C_{23} E\left(C_{3 U}\right)}{D}, \\
&amp; E\left(b_3\right)=\beta_3+\frac{V_2 E\left(C_{3 U}\right)}{D}-\frac{C_{23} E\left(C_{2 U}\right)}{D} .
\end{aligned}
\]</span> Our estimates will be unbiased if <span class="math inline">\(E\left(C_{2 U}\right)=0=E\left(C_{3 U}\right)\)</span>. The development concentrates upon these terms, where <span class="math display">\[
\begin{aligned}
&amp; E\left(C_{2 U}\right)=E\left[\frac{1}{n} \sum_i\left(X_{i 2}-\bar{X}_2\right)\left(U_i-\bar{U}\right)\right] \\
&amp; E\left(C_{3 U}\right)=E\left[\frac{1}{n} \sum_i\left(X_{i 3}-\bar{X}_3\right)\left(U_i-\bar{U}\right)\right]
\end{aligned}
\]</span></p>
</div>
</div>
</div>
</section>
<section id="v4.-voll-spezifizierte-modelle" class="level4" data-number="2.3.2.2">
<h4 data-number="2.3.2.2" class="anchored" data-anchor-id="v4.-voll-spezifizierte-modelle"><span class="header-section-number">2.3.2.2</span> V4. Voll spezifizierte Modelle</h4>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
IYI: Ableitung für <strong><span class="math inline">\(E(U_i-\overline{U}) = 0.\)</span></strong>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{aligned}
b_1 &amp; =\bar{Y}-b_2 \bar{X}_2-b_3 \bar{X}_3=\beta_1+\beta_2 \bar{X}_2+\beta_3 \bar{X}_3+\bar{U}=b_2 \bar{X}_2-b_3 \bar{X}_3 \\
&amp; =\beta_1+\left(\beta_2-b_2\right) \bar{X}_2+\left(\beta_3-b_3\right) \bar{X}_3+\bar{U}_1
\end{aligned}
\]</span></p>
<p><span class="math display">\[
E\left(b_1\right)=E\left(\beta_1\right)+E\left(\beta_2-b_2\right) \bar{X}_2+E\left(\beta_3-b_3\right) \bar{X}_3+E(\bar{U}) .
\]</span> This expression will equal <span class="math inline">\(\beta_1\)</span> if two conditions hold. If <span class="math inline">\(U_i\)</span> is distributed independently of <span class="math inline">\(X_2\)</span> and <span class="math inline">\(X_3\)</span>, then our estimates <span class="math inline">\(b_2\)</span> and <span class="math inline">\(b_3\)</span> are unbiased so that <span class="math inline">\(E\left(\beta_2-b_2\right)=E\left(\beta_3-b_3\right)=0\)</span>. Secondly, the expected value of <span class="math inline">\(\bar{U}\)</span> must equal zero, <span class="math inline">\(E(\bar{U})=0\)</span>. If both conditions hold, <span class="math inline">\(E\left(b_1\right)=\beta_1\)</span>. Thus, for all estimated coefficients to be unbiased, we modify assumption A.3 to be <span class="math inline">\(E\left(U_i\right)=0\)</span>. Note that this is a stronger assumption than is needed for unbiasedness of the slope coefficients. <span class="math inline">\(^3\)</span> Arithmetic Properties Unfortunately, we cannot test either of these assumptions, <span class="math inline">\(E(\bar{U})=0\)</span> and <span class="math inline">\(\sum\left(X_{i k}-\bar{X}_k\right)\left(U_i-\bar{U}\right)=0\)</span>, with the observed data. Intuitively, one would test these assumptions by examining the mean of the residuals from the estimated equations and the correlation between these residuals and <span class="math inline">\(X\)</span>. Our intuition, however, is wrong in this case. The mean of the residuals is <span class="math display">\[
\frac{1}{n} \sum_{i=1}^n\left(Y_i-\hat{Y}_i\right)=\frac{1}{n} \sum\left(Y_i-b_1-b_2 X_{i 2}-b_3 X_{3 t}\right)
\]</span> However, this is simply <span class="math inline">\(-1 / n\)</span> times Eq. (2.11) which by construction equals zero. Thus the mean of the estimated residuals must be zero, whether or not the mean of the true errors is zero.</p>
<p>Since <span class="math inline">\(\bar{e}=0\)</span>, the numerator of the correlation between the residuals and <span class="math inline">\(X_2\)</span> is <span class="math display">\[
\begin{aligned}
\frac{1}{n} \sum e_i\left(X_{i 2}-\bar{X}_2\right) &amp; =\frac{1}{n} \sum\left(Y_i-\hat{Y}_i\right)\left(X_{i 2}-\bar{X}_2\right) \\
&amp; =\frac{1}{n} \sum\left(Y_i-\hat{Y}_i\right) X_{i 2}-\frac{1}{n} \sum\left(Y_i-\hat{Y}_i\right) \bar{X}_2 \\
&amp; =\frac{1}{n} \sum\left(Y_i-b_1-b_2 X_{i 2}-b_3 X_{i 3}\right)\left(X_{i 2}\right)-\frac{1}{n} \bar{X}_2 \sum e_i
\end{aligned}
\]</span></p>
</div>
</div>
</div>
<p>Unsere B’s sind nur dann unverzerrt, wenn das Modell voll spezifiziert ist in Bezug auf Einflüsse, die mit unseren B’s in Wirklichkeit zusammenhängen. Wenn wir vergessen in unsere Überlegungen und Messungen einzubeziehen, dass die Storchenpopulation einer Gegend nur darum mit der Geburtenrate zu tun hat, weil in ländlichen Regionen die Geburtenrate höher ist und mehr Störche leben als in der Stadt; wenn wir also diesen Dritteinfluss vergessen, dann scheint es einen Zusammenhang zwischen Geburtenrate und Storchenpopulation zu geben. Wir würden falsche Schlüsse ziehen, weil der Zusammenhang verzerrt geschätzt würde. Journalistinnen vom Berliner Kurier könnten glauben, dass der Storch die Kinder bringt. Wir müssen also theoretisch erarbeiten, welche Einflüsse von Bedeutung sein könnten für unsere AV oder den Zusammenhang zwischen den UVs und der AV beeinflussen könnten. Das ist Theoriearbeit. Dieser Zusammenhang muss sich auch mathematisch in der Statistik abbilden, was er auch tut.</p>
<p>Wenn wir mal annehmen, dass die wahren Zusammenhänge gut durch die Formel @ref(eq:Spez1) dargestellt wären, aber die Theorie zu dem Thema auf dem Stand ist, dass die einfacheren Zusammenhänge aus der Formel @ref(eq:Spez2) gelten, also eine wichtige Einflussgrösse (<span class="math inline">\(X_4\)</span>) nicht berücksichtigt wurde. Wenn dem so wäre, dann würde das Unbekannte (<span class="math inline">\(U_i\)</span>) in Formel @ref(eq:Spez2) nicht nur den einfachen stochastischen Rest umfassen, sondern zusätzlich <span class="math inline">\(\beta_4X_{i4}\)</span>. Dann wäre der Erwartungswert (also der Wert, um den unsere Stichprobenparameter b streuen) nicht mehr das erhoffte <span class="math inline">\(\beta_2\)</span> sondern <span class="math inline">\(\beta_2 + \beta_4b_{42}\)</span>, wie in Formel @ref(eq:Spez3). Das würde zu einem Fehler führen, der bei <span class="math inline">\(\frac{r_{42}-r_{32}r_{43}}{1-r^2_{32}}\sqrt{\frac{V_4}{V_2}}\)</span> liegt. Wenn wir also ewig Stichproben ziehen würden und jedes Mal ein <span class="math inline">\(b_2\)</span> bestimmen würden, dann würden diese <span class="math inline">\(b_2\)</span>s nicht um <span class="math inline">\(\beta_2\)</span> streuen. Das Mass, um das wir uns verschätzen würden, wäre so gross wie in @ref(eq:Spez4) notiert. Auch unsere Signifikanztests wären falsch und die Konfidenzintervalle würden an der falschen Stelle liegen. Unsere ganze Analyse wäre falsch.</p>
<span class="math display">\[\begin{align}
  \text{wahr:} Y_i=&amp;\beta_1 + \beta_2X_{i2} + \beta_3X_{i3} + \beta_4X_{i4}+U_i \label{eq:Spez1}\\
  \text{geschätzt: } Y_i=&amp;\beta_1 + \beta_2X_{i2} + \beta_3X_{i3}
                          +U^\star_i \text{\qquad wobei \quad } U^\star_i = \beta_4X_{i4}+U_i \label{eq:Spez2}\\
  \text{also: } E(b_2) =&amp; \beta_2 + \beta_4b_{42} \label{eq:Spez3}\\
  \text{mit: }
  b_{42}=&amp;\frac{r_{42}-r_{32}r_{43}}{1-r^2_{32}}\sqrt{\frac{V_4}{V_2}} \label{eq:Spez4}
\end{align}\]</span>
<p>Wie geht man nun mit dieser Tyrannei um, dass man alle Einflüsse kennen sollte, die schlicht unbekannt sind. Nur Chuck Norris weiss, wann ein Modell voll spezifiziert ist. Wir können nie wissen, wann wir am Ende der Wissenschaft angekommen sind, weil wir alles vollständig und für immer gültig spezifiziert haben. Es geht bei dieser Überlegung der Spezifikation mehr darum, dass wir die Spezifikation der bestehenden Modelle verbessern. Das kann heissen, dass wir falsche Alltagsvorstellungen korrigieren, indem wir den Kindern irgendwann sagen, dass das bivariate Regressionsmodell mit den Störchen und den Kindern, nicht voll spezifiziert ist und Sex, Verhütung und viele mehr einen gewissen Einfluss hat auf die Geburtenrate. Wir klären aber nicht nur in der Alltagswelt auf, sondern verbessern auch unsere Modelle stetig, indem wir uns fragen, welche Einflussgrössen bei der Erklärung eines Phänomens noch eine Rolle spielen könnten.</p>
<p>Die statistisch, mathematische Anforderung an die Modellspezifikation bedeutet also, dass wir unsere Theorie gut und gründlich entwickeln müssen. Bei einer schlechten Theorie und entsprechend zu wenig erfasster oder einbezogener Modells sind unsere Ergebnisse verzerrt und damit falsch oder mindestens nicht state of the art. Darum muss man immer erst schauen, was der Forschungsstand ist. Der kann repliziert und damit kontrolliert werden, und wenn wir das Modell weiter spezifizieren und neue Ergebnisse erlangen, dann haben wir die Theorie erweitert und einen wissenschaftlichen Mehrwert geschaffen. Es werden auch noch Generationen nach uns und Ihnen kommen, die unsere Theorien überarbeiten und dabei feststellen, dass wir unserer Modelle unterspezifiziert hatten. Das ist dann der wissenschaftliche und zivilisatorische Fortschritt. Wissenschaft wird also nicht irgendwann fertig sein und wichtig bleiben.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
IYI: Ableitung Modellspezifikation
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>the true model <span class="math inline">\(Y_i=\beta_1+\beta_2 X_{i 2}+\beta_3 X_{i 3}+\beta_4 X_{i 4}+U_i\)</span>. When such a misspecification occurs, the influence attributed to the included variables is actually a combined influence of the included and excluded variables. For example, if all <span class="math inline">\(X\)</span> variables exert a positive influence on <span class="math inline">\(Y_i\)</span> and these variables are themselves positively correlated, the estimated coefficients for the included variables will be overstated and imply that each included variable is more important than it actually is. The mathematics of this case is straightforward. Assume that the true model is <span class="math display">\[
Y_i=\beta_1+\beta_2 X_{i 2}+\beta_3 X_{i 3}+\beta_4 X_{i 4}+U_i,
\]</span> and that instead we estimate <span class="math display">\[
Y_i=\beta_1+\beta_2 X_{i 2}+\beta_3 X_{i 3}+U_i^* \quad \text { where } \quad U_i^*=\beta_4 X_{i 4}+U_i
\]</span> The least squares estimators from Chapter 2 are <span class="math display">\[
\begin{aligned}
&amp; b_2=\frac{V_3 C_{2 Y}-C_{23} C_{3 Y}}{V_2 V_3-C_{23}^2}=\beta_2+\frac{V_3 C_{2 U^*}-C_{23} C_{3 U^*}}{V_2 V_3-C_{23}^2}, \\
&amp; b_3=\frac{V_2 C_{3 Y}-C_{23} C_{2 Y}}{V_2 V_3-C_{23}^2}=\beta_3+\frac{V_2 C_{3 U^*}-C_{23} C_{2 U^*}}{V_2 V_3-C_{23}^2} .
\end{aligned}
\]</span> Substituting <span class="math inline">\(U_i^*=\beta_4 X_{i 4}+U_i\)</span> into the covariance expressions involving <span class="math inline">\(U^*\)</span> gives <span class="math display">\[
\begin{aligned}
C_{2 U^*} &amp; =\frac{1}{n} \sum\left(X_{i 2}-\bar{X}_2\right)\left(U_i^*-\bar{U}^*\right)=\frac{1}{n} \sum\left(X_{i 2}-\bar{X}_2\right)\left(\beta_4 X_{i 4}+U_i-\beta_4 \bar{X}_4-\bar{U}\right) \\
&amp; =\frac{1}{n} \beta_4 \sum\left(X_{i 2}-\bar{X}_2\right)\left(X_{i 4}-\bar{X}_4\right)+\frac{1}{n} \sum\left(X_{i 2}-\bar{X}_2\right)\left(U_i-\bar{U}\right) \\
&amp; =\beta_4 C_{24}+C_{2 U} \\
C_{3 U^*} &amp; =\beta_4 C_{34}+C_{3 U}
\end{aligned}
\]</span> Taking the expected value of <span class="math inline">\(b_2\)</span> and <span class="math inline">\(b_3\)</span>, assuming fixed <span class="math inline">\(X\)</span> and <span class="math inline">\(E\left(U_i\right)=0\)</span>, we obtain <span class="math display">\[
\begin{aligned}
&amp; E\left(b_2\right)=\beta_2+\beta_4\left(\frac{V_3 C_{24}-C_{23} C_{34}}{V_2 V_3-C_{23}^2}\right)+E\left[\frac{V_3 C_{2 U}-C_{23} C_{3 U}}{V_2 V_3-C_{23}^2}\right]=\beta_2+\beta_4 b_{42} \\
&amp; E\left(b_3\right)=\beta_3+\beta_4\left(\frac{V_2 C_{34}-C_{23} C_{24}}{V_2 V_3-C_{23}^2}\right)+E\left[\frac{V_2 C_{3 U}-C_{23} C_{2 U}}{V_2 V_3-C_{23}^2}\right]=\beta_3+\beta_4 b_{43}
\end{aligned}
\]</span> where <span class="math display">\[
b_{42}=\frac{\left(r_{42}-r_{32} r_{43}\right)}{1-r_{32}^2} \sqrt{\frac{V_4}{V_2}} \quad \text { and } \quad b_{43}=\frac{\left(r_{43}-r_{32} r_{42}\right)}{1-r_{32}^2} \sqrt{\frac{V_4}{V_3}} \text {. }
\]</span></p>
</div>
</div>
</div>
</section>
<section id="keine-perfekte-oder-heftige-multikollinearität-v5." class="level4" data-number="2.3.2.3">
<h4 data-number="2.3.2.3" class="anchored" data-anchor-id="keine-perfekte-oder-heftige-multikollinearität-v5."><span class="header-section-number">2.3.2.3</span> Keine perfekte oder heftige Multikollinearität (V5.)</h4>
<p>Wenn perfekte Multikollinearität vorliegt, dann kann eine Variable perfekt aus den übrigen Variablen vorhergesagt werden (technischer: eine UV ist eine Linearkombination der übrigen UVs). Ein lineares Modell gibt dann keine Antwort auf die ihm gestellte Frage, wenn zwei UVs identisch sind, also untrennbar verwoben. Das liegt daran, dass die Frage an das lineare Modell ist: «Wie starkt ist der Effekt jeder einzelnen UV, wenn die Effekte der übrigen UV herausgerechnet werden?». Wenn eine Variable eine Linearkombination der übrigen Variablen ist, dann bleibt von ihr exakt nichts übrig, wenn die Linearkombination der übrigen Variablen aus ihr herausgerechnet werden. Ist ihre Varianz dadurch 0, ist sie im Grunde eine Konstante, und wie in <a href="#sec:V1">V1.</a> diskutiert, kann mit Konstanten keine Kovarianz und damit auch kein lineares Modell gerechnet werden. Jedes Statistikprogramm würde also an dieser Stelle aussteigen und ihnen sagen, dass das Modell so nicht gerechnet werden kann, weil perfekte Multikollinearität vorliegt. Das muss also nicht extra getestet werden.</p>
<p>Perfekte Multikollinearität entsteht meistens, wenn eine Variable aus dem Rohdatensatz umkodiert wurde und die Originalvariable und die einfach umkodierte mit im Modell sind. Die schuldige Variable findet man recht schnell. Etwas weniger direkt ersichtlich ist so eine perfekte Multikollinearität durch Datenaufbereitung, wenn ein Index und alle Variablen, aus denen der Index berechnet wurden, mit in das Modell aufgenommen wurden. Wenn Sie also z.B. die Durchschnittsnote im Abi in das Modell packen und alle Noten der einzelnen Fächer auch, die zusammen exakt die Durchschnittsnote ergeben. Suchen Sie in solchen Fällen nach den Indizes. Wenn Sie in dem Beispiel die Durchschnittsnote rausnehmen oder ein paar Fächer, die ihnen für die Erklärung der AV nicht so wichtig erscheinen, dann wird das Problem der perfekten Multikollinearität schnell gelöst sein.</p>
<p>Etwas Multikollinearität ist allerdings nicht nur erlaubt, sondern der Grund dafür, dass wir multivariate Modelle rechnen. Wären die UVs untereinander alle unkorreliert, dann wären alle B’s dieselben, wenn nur bivariate Regressionen gerechnet werden würden. In der Formel @ref(eq:Bs1) für <span class="math inline">\(b_2\)</span> sieht man das auch sehr gut: Wenn <span class="math inline">\(r_{23} = 0\)</span>, also keine Multikollinearität beim Modell mit zwei UVs (<span class="math inline">\(X_2\)</span> und <span class="math inline">\(X_3\)</span>), dann kommt für <span class="math inline">\(b_2\)</span> dasselbe raus, wie ohne <span class="math inline">\(X_3\)</span> (in @ref(eq:Bs1) wird $r_{23} = 0 gesetzt und in @ref(eq:Bs3) sieht man, dass <span class="math inline">\(X_3\)</span> oder <span class="math inline">\(r_3\)</span> keine Rolle spielen).</p>
<span class="math display">\[\begin{align}
   b_2&amp; = \frac{r_{Y2}-r_{23}r_{Y3}}{(1-r_{23}^2)}\frac{S_y}{S_2} \label{eq:Bs1}\\
   b_2&amp; = \frac{r_{Y2}-0\cdot r_{Y3}}{(1-0^2)}\frac{S_y}{S_2} \label{eq:Bs2}\\
   b_2&amp; = r_{Y2}\frac{S_y}{S_2} \label{eq:Bs3}
\end{align}\]</span>
<p>Wenn es etwas Multikollinearität gibt, wird das Produkt aus <span class="math inline">\(r_{23}r_{Y3}\)</span> aus dem bivariaten <span class="math inline">\(b_2\)</span> subtrahiert (herausgerechnet). Zusätzlich wird mit einer Korrektur unter dem Bruchstrich von <span class="math inline">\(1-r^2_{23}\)</span> angepasst. In Worten bedeutet das so viel wie: Wenn wir untersuchen wollen, ob der Storch (UV) die Kinder bringt (AV), aber wissen, dass das auch noch mit Urbanität (<span class="math inline">\(X_3\)</span>) zusammenhängt, dann müssen wir berücksichtigen (herausrechnen) wie stark Urbanität (<span class="math inline">\(X_3\)</span>) und Storchenpopulation (<span class="math inline">\(X_2\)</span>) zusammenhängen (<span class="math inline">\(r_23\)</span>), wenn bzw. in dem Masse, wie auch die Geburtenrate (Y) mit der Urbanität zusammenhängt (<span class="math inline">\(r_{Y2}\)</span>). Das steht über dem Bruch der Formel @ref(eq:Bs1). Da wir nicht mehr mit den vollen 100% der Varianz von <span class="math inline">\(X_2\)</span> rechnen können, wird unter dem Bruchstrich der Formel @ref(eq:Bs1) auch noch herausgerechnet, um wie viel <span class="math inline">\(X_2\)</span> durch <span class="math inline">\(X_3\)</span> beklaut wird (<span class="math inline">\(1-r^2_{23}\)</span>). Über diesen Teil der Formel lohnt es sich, etwas länger nachzudenken.</p>
<p><strong>Toleranz und VIF</strong></p>
<p>Wenn Multikollinearität bedeutet, dass eine Variable durch eine andere stark bestimmt wird, haben wir für die Bestimmtheit einer Variablen durch andere ein Mass: Das Bestimmtheitsmass <span class="math inline">\(R^2\)</span>. In der Formel @ref(eq:Bs1) steht unter dem Bruch ein <span class="math inline">\(r^2_{23}\)</span>, das man besser auch schreiben könnte als <span class="math inline">\(R^2_{2.3}\)</span>, einfach um deutlicher zu machen, dass es um eine multiple Korrelation geht und darum, dass die Regression auf <span class="math inline">\(X_2\)</span> gemeint ist, von allen übrigen Variablen. Wenn es mehr als nur die <span class="math inline">\(X_3\)</span> gibt, würden wir in der Formel für <span class="math inline">\(b_2\)</span> schreiben <span class="math inline">\(R^2_{2.34567...}\)</span> und bei <span class="math inline">\(b_3\)</span> <span class="math inline">\(R^2_{3.24567...}\)</span>. Nun ist Multikollinearität nichts Gutes, sondern ein Problem. Darum steht in Formel @ref(eq:Bs1) auch <span class="math inline">\(1-r^2_{23}\)</span>. Hier ist also angegeben, wie viel von den 100% Varianz von <span class="math inline">\(b_2\)</span> übrig bleiben, wenn man herausgerechnet hat, wie stark die übrigen UVs die Variable <span class="math inline">\(X_2\)</span> bestimmen (<span class="math inline">\(R^2_{2.34567...}\)</span>). Man könnte auch sagen, dass damit für die Multikollinearität angegeben ist, wie stark ihre Toleranz gegenüber den übrigen Variablen ist. Wenn also zum Beispiel die übrigen Variablen 40% der Variable <span class="math inline">\(X_2\)</span> erklären, dann wäre die Toleranz <span class="math inline">\(1-0.4\)</span>, also 60%. Diesen Toleranzwert (TOL) sollte man sich bei jeder Regression mit rausgeben lassen, um zu prüfen, wie stark die einzelnen Variablen von Multikollinearität betroffen sind. In Publikationen sieht man diese Werte oft nicht, weil sie von den Forschenden geprüft und für nicht problematisch befunden wurden (wenn diese Forschenden gründlich arbeiten).</p>
<p>Multikollinearität hat vor allem auch eine Bedeutung für die Fehlervarianz der B’s, also wie unsicher oder wackelig die b’s sind. Darum steckt in der Formel für die <span class="math inline">\(s_{b_2}^2\)</span> auch das <span class="math inline">\(1-R_{23}^2\)</span> unter dem Bruchstrich des Faktors drin, der hinten steht. Dieser hintere Faktor ist demnach der Faktor, um den die Fehlervarianz der B’s steigt, wenn die Toleranz (<span class="math inline">\(1-R_{2.3}^2\)</span>) klein ist, weil die jeweilige UV stark durch die übrigen Variablen bestimmt wird (<span class="math inline">\(R_{2.3}^2\)</span>). Mit diesem Faktor wird auch gearbeitet, indem in Regressionsanalysen in Outputs häufig der <strong>V</strong>arianz-<strong>I</strong>nflations-<strong>F</strong>aktor (VIF) mit angezeigt wird. Wenn also zum Beispiel die Varianz der Variablen <span class="math inline">\(X_2\)</span> zu 90% durch die übrigen Variablen im Modell aufgeklärt wird, dann ist die Wert TOL nur noch <span class="math inline">\(1-.9 = .1\)</span>. Der Variablen <span class="math inline">\(X_2\)</span> würden also nur noch 10% seiner Ursprungsvarianz bleiben, um die AV erklären zu können. Das ist nicht viel, worauf eine stabile Regressionsgerade angepasst werden könnte. Darum wackelt das <span class="math inline">\(b_2\)</span> viel mehr, als wenn die anderen Variablen nicht berücksichtigt worden wären. Die Unsicherheit wurde um den Faktor <span class="math inline">\(\frac{1}{1-R^2_{2.34567...}}\)</span> inflationiert, also um das Zehnfache! Da muss man sich dann schon fragen, was da eigentlich übrig bleibt.</p>
<span class="math display">\[\begin{align}
  s_{b_2}^2&amp;=\frac{s^2}{n}\cdot\frac{1}{V_2}\cdot\frac{1}{1-R_{2.3}^2} \label{eq:sb1}\\
  s_{b_3}^2&amp;=\frac{s^2}{n}\cdot\frac{1}{V_3}\cdot\frac{1}{1-R_{3.2}^2} \label{eq:sb2}
\end{align}\]</span>
</section>
</section>
<section id="homoskedastizität-v6." class="level3" data-number="2.3.3">
<h3 data-number="2.3.3" class="anchored" data-anchor-id="homoskedastizität-v6."><span class="header-section-number">2.3.3</span> Homoskedastizität (V6.)</h3>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
IYI: Effizienz als Varianz von <span class="math inline">\(b_2\)</span> und <span class="math inline">\(b_3\)</span>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Assuming that <span class="math inline">\(b_2\)</span> is unbiased (or that assumption A.3 holds), the variance of our estimator <span class="math inline">\(b_2\)</span> can be found from a rearrangement of Eq. (3.1): <span class="math display">\[
\begin{gathered}
b_2-\beta_2=\frac{V_3 C_{2 U}-C_{23} C_{3 U}}{D} \\
\operatorname{var}\left(b_2\right)=E\left[b_2-E\left(b_2\right)\right]^2=E\left(b_2-\beta_2\right)^2=E\left(\frac{V_3 C_{2 U}-C_{23} C_{3 U}}{D}\right)^2 \\
=\frac{1}{D^2} E\left(V_3^2 C_{2 U}^2-2 V_3 C_{23} C_{2 U} C_{3 U}+C_{23}^2 C_{3 U}^2\right) \\
=\frac{1}{D^2}\left[V_3^2 E\left(C_{2 U}^2\right)-2 V_3 C_{23} E\left(C_{2 U} C_{3 U}\right)+C_{23}^2 E\left(C_{3 U}^2\right)\right]
\end{gathered}
\]</span> (Note, by assumption A.2, the <span class="math inline">\(X\)</span> values are fixed.) We need to investigate the three expected value terms in detail: <span class="math display">\[
\begin{aligned}
&amp; E\left(C_{2 U}^2\right)=E\left\{\frac{1}{n^2}\left[\sum\left(X_{i 2}-\bar{X}_2\right)\left(U_i-\bar{U}\right)\right]^2\right\} \\
&amp;=\frac{1}{n^2} E {\left[\left(X_{12}-\bar{X}_2\right)\left(U_1-\bar{U}\right)+\left(X_{22}-\bar{X}_2\right)\left(U_2-\bar{U}\right)\right.} \\
&amp;\left.+\cdots+\left(X_{n 2}-\bar{X}_2\right)\left(U_T-\bar{U}\right)\right]^2
\end{aligned}
\]</span> (from expanding the summation) <span class="math display">\[
\begin{aligned}
&amp;=\frac{1}{n^2} E\left[\sum_{i=1}^n\left(X_{i 2}-\bar{X}_2\right)^2\left(U_i-\bar{U}\right)^2\right. \\
&amp;\left.+2 \sum_{i=1}^{n-1} \sum_{s=t+1}^n\left(X_{i 2}-\bar{X}_2\right)\left(X_{s 2}-\bar{X}_2\right)\left(U_i-\bar{U}\right)\left(U_s-\bar{U}\right)\right]
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
&amp;=\frac{1}{n^2}[ \sum_{i=1}^n\left(X_{i 2}-\bar{X}_2\right)^2 E\left(U_i-\bar{U}\right)^2 \\
&amp;\left.+2 \sum_{i=1}^n \sum_{s=t+1}^n\left(X_{i 2}-\bar{X}_2\right)\left(X_{s 2}-\bar{X}_2\right) E\left(U_i-\bar{U}\right)\left(U_s-\bar{U}\right)\right] \\
&amp; \text { (from fixed } X \text { 's) } \\
&amp;= \frac{1}{n^2}\left[\sum\left(X_{i 2}-\bar{X}_2\right)^2 \sigma_i^2+2 \sum \sum\left(X_{i 2}-\bar{X}_2\right)\left(X_{s 2}-\bar{X}_2\right) \sigma_{i s}\right], \text { (3.6) }
\end{aligned}
\]</span> where <span class="math inline">\(\sigma_i^2=E\left(U_i-\bar{U}\right)^2\)</span> and <span class="math inline">\(\sigma_{i s}=E\left(U_i-\bar{U}\right)\left(U_s-\bar{U}\right)\)</span>. Similar expressions for <span class="math inline">\(E\left(C_{2 U} C_{3 U}\right)\)</span> and <span class="math inline">\(E\left(C_{3 U}^2\right)\)</span> are <span class="math display">\[
\begin{aligned}
&amp; E\left(C_{3 U}^2\right)=\frac{1}{n^2}\left[\sum\left(X_{i 3}-\bar{X}_3\right)^2 \sigma_i^2+2 \sum \sum\left(X_{i 3}-\bar{X}_3\right)\left(X_{s 3}-\bar{X}_3\right) \sigma_{i s}\right], \\
&amp; E\left(C_{2 U} C_{3 U}\right)=\frac{1}{n^2}\left[\sum\left(X_{i 2}-\bar{X}_2\right)\left(X_{i 3}-\bar{X}_3\right) \sigma_i^2\right. \\
&amp; \left.+2 \sum \sum\left(X_{i 2}-\bar{X}_2\right)\left(X_{s 3}-\bar{X}_3\right) \sigma_{i s}\right] \text {. } \\
&amp;
\end{aligned}
\]</span> These expressions are quite complicated, but they can be simplified with two more assumptions about the distribution of the errors. These assumptions, however, are not employed just to simplify the algebra. They are also important for developing the properties of the OLS estimator relative to other estimators. If all error terms have the same variance (we have already assumed they have the same mean), then A.4a <span class="math display">\[
E\left(U_i-\bar{U}\right)^2=\sigma_i^2=\sigma^2 \quad \text { for all } t .
\]</span> Further, if all the error terms are drawn independently of each other so that all the possible error terms associated with one observation are independent of, and thus uncorrelated with, the error terms at other observations, then A.4b <span class="math display">\[
E\left(U_i-\bar{U}\right)\left(U_s-\bar{U}\right)=\sigma_{i s}=0 \quad \text { for } \quad t \neq s .
\]</span> With these two assumptions, or restrictions on the error terms, the above simplify to <span class="math display">\[
\begin{aligned}
&amp; E\left(C_{2 U}^2\right)=\frac{1}{n^2} \sum\left(X_i-X_2\right)^2 \sigma^2=\frac{\sigma^2 V_2}{n}, \\
&amp; E\left(C_{3 U}^2\right)=\frac{\sigma^2 V_3}{n},
\end{aligned}
\]</span></p>
<p>When these are substituted into Eq. (3.5), we get <span class="math display">\[
\begin{aligned}
\operatorname{var}\left(b_2\right) &amp; =\frac{\sigma^2}{n D^2}\left[V_3^2 V_2-2 V_3 C_{23}^2+C_{23}^2 V_3\right]=\frac{\sigma^2 V_3}{n D^2}\left[V_3 V_2-C_{23}^2\right] \\
&amp; =\frac{\sigma^2 V_3}{n D}=\frac{1}{n} \sigma^2\left[\frac{V_3}{V_2 V_3-C_{23}^2}\right]=\frac{\sigma^2}{n}\left[\frac{1 / V_2}{1-r_{23}^2}\right] .
\end{aligned}
\]</span> The similar expression for <span class="math inline">\(\operatorname{var}\left(b_3\right)\)</span> is <span class="math display">\[
\operatorname{var}\left(b_3\right)=\frac{1}{n} \sigma^2\left[\frac{V_2}{V_2 V_3-C_{23}^2}\right]=\frac{\sigma^2}{n}\left[\frac{1 / V_3}{1-r_{23}^2}\right] .
\]</span> [A useful exercise for the student is to show for the bivariate case that <span class="math inline">\(\left.\operatorname{var}\left(b_2\right)=\sigma^2 / \Sigma\left(X_i-\bar{X}\right)^2=\sigma^2 / n \operatorname{var}(X).\right]\)</span></p>
</div>
</div>
</div>
<p>Homoskedastizität bedeutet, dass die Streuung der Fehler um die Regressionsgerade überall ungefähr gleich (homo) gross sein sollte. Heteroskedastizität bedeutet, dass die Fehlerstreuung um unsere Regressionsgerade mit der grösse unserer UVs unterschiedlich ist, also z.B. grösser wird, weil Kodierer:innen wenn sie sehr lange nacheinander (weil vielleicht in letzter Minute) kodieren, mit der Zeit immer mehr Fehler machen. Oder weil Kodierer:innen regelmässig ein bisschen kodieren und dabei immer besser werden und immer weniger Fehlerstreuung entsteht. Wenn diese Streuung um die Regressionsgerade mit einer Variablen korreliert wie in Abb. @ref(fig:Heteroskedastizitaet), dann sind die Standardfehler der b’s nicht gut und gültig geschätzt. Mithin sind die t-Werte nicht korrekt, damit die p-Werte und Konfidenzintervalle falsch und schliesslich unsere Entscheidung über die Gültigkeit oder auch die Entscheidbarkeit der Hypothese (H0 oder H1) falsch.</p>
<div class="cell" data-hash="02_GLM_cache/html/Heteroskedastizitaet_391276c765c4d7cafce52c612f809ef8">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/Heteroskedastizitaet.jpg" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Heteroskedastizität</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Neben diesem breiter oder schmaler werden der Streuung um die Regressionsgerade entsteht Heteroskedastizität oftmals, wenn wir eine Gerade in einen kurvlinearen Zusammenhang einpassen. In der Abb. @ref(fig:Hetero-Nicht-Linearitaet) ist gut zu erkennen, dass in (a) die Verteilung der standardisierten Fehler recht gleichmässig ist. In (b) geht eben die Schultüte (bzw. Tüte Marroni) auseinander und stellt damit Heteroskedastizität dar. In (c) kommt die Heteroskedastizität durch eine erzwungene Gerade bei gegebener kurvlinearer Beziehung zwischen den Variablen (das sieht in (b) recht kubisch aus). In (d) wäre es beides zusammen, also ein (vermutlich quadratischer) Zusammenhang, bei dem mit steigendem X auch noch die Streuung steigt.</p>
<div class="cell" data-hash="02_GLM_cache/html/Hetero-Nicht-Linearitaet_1acb2fb9cdb1cb7fb4ee4f4800018ee5">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/HeteroskedastizitaetUndLinearitaet.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Nicht-Linearität der Beziehungen</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Lösen kann man die Probleme mit der Heteroskedastizität, indem man GLS rechnet, also (<strong>G</strong>eneralized <strong>L</strong>east <strong>Squares</strong>) und dabei zunächst das korrekte b bestimmst, dann die Streuung berechnet und im 2-Stage-Least-Squares mit den gewichteten Residuen rechnen würde. Das zu vermitteln geht über diesen Kurs hinaus. Einfacher ist es mit den kurvilinearen Beziehungen. Die können wir linearisieren. Wir schauen uns also die Verteilung der Residuen an und wenn wir da so eine kurvlineare Beziehung sehen, dann modellieren wir die so, dass sie linear geschätzt werden kann. Das ist gut in Abb. @ref(fig:Kurvlineare) abgebildet. Dabei ist nicht entscheidend, dass Sie jetzt schon den Aufbau der Formel verstehen, sondern, dass es komplexere Formeln gibt als die einfache additiv lineare, und durch diese Formeln doch wieder das lineare Modell angewendet werden kann, weil die Formeln für eine «Linearisierung» (Transformation) sorgen.</p>
<div class="cell" data-hash="02_GLM_cache/html/Kurvlineare_2543ac5617c66d0bb8b108bbc91fba77">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/HJTeil4.jpg" class="img-fluid figure-img" style="width:90.0%"></p>
<p></p><figcaption class="figure-caption">Linearisierung kurvlinearer Beziehungen</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
IYI: Herleitung, wann OLS «Best» ist
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The proof that <span class="math inline">\(b_2\)</span> is best is only sketched here. A complete proof is shown in Appendix 5.1. The proposition to be demonstrated is that, among all linear and unbiased estimators of <span class="math inline">\(\beta_2\)</span> and <span class="math inline">\(\beta_3\)</span>, the least squares estimators <span class="math inline">\(b_2\)</span> and <span class="math inline">\(b_3\)</span> have the minimum variance when assumptions A.1-A.4 hold. We first define an arbitrary linear estimator <span class="math inline">\(b_2^{\#}\)</span>. Linear refers to the fact that the estimator is a linear function of the <span class="math inline">\(Y_i, b_2^{\#}=\Sigma C_{i 2}^{\#}\left(Y_i-\bar{Y}\right)\)</span>, where <span class="math inline">\(C_{i 2}^{\#}\)</span> is any set of weights. (The weights are <span class="math display">\[
C_{i 2}=\frac{1}{n} \frac{V_3\left(X_{i 2}-\bar{X}_2\right)-C_{23}\left(X_{i 3}-\bar{X}_3\right)}{D}
\]</span> for the least squares estimator of <span class="math inline">\(\beta_2\)</span>.) With complete generality, we can write <span class="math inline">\(C_{i 2}^{\#}\)</span> as the least squares weight plus an arbitrary number <span class="math inline">\(g_{i 2}, C_{i 2}^{\#}=C_{i 2}+g_{i 2}\)</span>. The restriction of unbiasedness implies that <span class="math inline">\(E\left[\Sigma C_{i 2}^{\#}\left(Y_i-\bar{Y}\right)\right]=\beta_2\)</span>. However, for OLS we showed that <span class="math inline">\(E\left[\Sigma C_{i 2}\left(Y_i-\bar{Y}\right)\right]=\beta_2\)</span>. This implies that <span class="math inline">\(E\left[\Sigma g_{i 2}\left(Y_i-\right.\right.\)</span> <span class="math inline">\(\bar{Y})]=0\)</span> since <span class="math inline">\(E\left[\Sigma C_{i 2}^{\#}\left(Y_i-\bar{Y}\right)\right]=E\left[\Sigma C_{i 2}\left(Y_i-\bar{Y}\right)+\Sigma g_{i 2}\left(Y_i-\bar{Y}\right)\right]\)</span>. Using this restriction and assumption A.4, the variance of <span class="math inline">\(b_2^{\#}\)</span> is <span class="math display">\[
\operatorname{var}\left(b_2^{\#}\right)=\operatorname{var}\left(b_2\right)+\sigma^2 \sum_{i=1}^n g_{i 2}^2,
\]</span> where <span class="math inline">\(\operatorname{var}\left(b_2\right)\)</span> is the variance of the least squares estimator. Since <span class="math inline">\(g_{i 2}^2 \geqslant 0\)</span>, <span class="math inline">\(\operatorname{var}\left(b_2^{\#}\right)\)</span> cannot be less than the variance of the least squares estimator <span class="math inline">\(b_2\)</span>. Further, it can equal <span class="math inline">\(\operatorname{var}\left(b_2\right)\)</span> only if each perturbation <span class="math inline">\(\left(g_{i 2}\right)\)</span> from the least squares weight is identically zero. (Similar developments can be done for <span class="math inline">\(b_1\)</span> and <span class="math inline">\(b_3\)</span>.)</p>
<p>An important aspect of this development, however, is that we have accepted and used the assumptions about the error distribution and fixed <span class="math inline">\(X\)</span> ’s. That is, this proof holds when <span class="math inline">\(E\left(U_i-\bar{U}\right)=0, E\left(U_i-\bar{U}\right)^2=\sigma^2\)</span>, and <span class="math inline">\(E\left(U_i-\right.\)</span> <span class="math inline">\(\bar{U})\left(U_s-\bar{U}\right)=0\)</span> for all <span class="math inline">\(i\)</span> and <span class="math inline">\(s \neq i\)</span>.</p>
</div>
</div>
</div>
</section>
<section id="verteilung-der-residuen-v7.-und-v8." class="level3" data-number="2.3.4">
<h3 data-number="2.3.4" class="anchored" data-anchor-id="verteilung-der-residuen-v7.-und-v8."><span class="header-section-number">2.3.4</span> Verteilung der Residuen (V7. und V8.)</h3>
<p>Ein Modell und die zugrundeliegenden Beziehungen ist oft dann gut, wenn die Verteilung der nicht erklärten Varianzanteile sich wie eine einfache Zufallsverteilung verhält bzw. wie Schrott.</p>
<section id="normalverteilung-der-fehler-v7." class="level4" data-number="2.3.4.1">
<h4 data-number="2.3.4.1" class="anchored" data-anchor-id="normalverteilung-der-fehler-v7."><span class="header-section-number">2.3.4.1</span> Normalverteilung der Fehler (V7.)</h4>
<p>Die Residuen (also der nicht erklärte Rest bzw. Modellfehler oder einfach Fehler) bezieht sich immer auf die nicht erklärte Streuung in der AV. Wenn wir also unser Modell haben und mit unseren Daten berechnen, dann bekommen wir vorhergesagte Werte und den Rest. Wenn wir den Rest anschauen, dann sollte der nicht zu stark von einer Normalverteilung abweichen.</p>
<p>In der Abb. @ref(fig:Hetero1) sieht man recht gut, dass links eine relativ gleichmässige Verteilung vorliegt, also kein Zusammenhang zwischen Fehlern und geschätzten Werten zu erkennen ist (Wäre perfekt 0, wenn die rote Linie exakt auf der gestrichelten Null-linie liegen würde.). Im zweiten Fall namens «Case 2» sieht man deutlich, dass es hier eine kuvlineare Abweichung gibt. Hier würde es sich sicher lohnen, ein quadratisches Modell anzupassen.</p>
<div class="cell" data-hash="02_GLM_cache/html/Hetero1_6a5ba3ee707929714f9ad2d79998120e">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diagnostics1.jpeg" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Residuen gegenüber Modell</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>In der Grafik @ref(fig:Hetero2) sind Normal Q-Q-Plots abgebildet. Bei dieser visuellen Darstellung werden die standardisierten Residuen gegen die theoretischen Quantile abgetragen, wobei «theoretisch» hier die zu erwartende Verteilung nach Wahrscheinlichkeitstheorie also nach Normalverteilung. Wenn die Punkte alle auf der Gerade liegen, dann ist der Normalverteilung der Residuen nicht stark widersprochen. Wenn sie, wie im zweiten Fall (typisch Case 2!) abweichen, dann ist die Annahme der Normalverteilung verletzt. Dann würden wir nach einem R-Paket suchen, das mit diesem Problem umgehen kann.</p>
<div class="cell" data-hash="02_GLM_cache/html/Hetero2_52353cf3193fc94dc16f2c1dec6295e1">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/diagnostics2.jpeg" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Normal Q-Q</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
IYI: Ableitung für <span class="math inline">\(U_i \sim N\left(0, \sigma^2\right)\)</span> .
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>If <span class="math inline">\(U_i \sim N\left(0, \sigma^2\right)\)</span>, and independent of <span class="math inline">\(U_s\)</span>, then the <span class="math inline">\(b\)</span> ’s, which are linear functions of <span class="math inline">\(U_i\)</span>, are normally distributed with a variance given in Eq. (3.5a), that is, <span class="math inline">\(b_2 \sim N\left(\beta_2, \sigma^2 / n V_2\left(1-r_{23}^2\right)\right)\)</span>. This implies that <span class="math display">\[
Z_2=\left(b_2-\beta_2\right) / \sigma_{b_2} \quad \text { and } \quad Z_3=\left(b_3-\beta_3\right) / \sigma_{b_3}
\]</span> are distributed according to the standard normal distribution <span class="math inline">\(N(0,1)\)</span>. (This distribution is discussed in Appendix I.) Since the Z’s are <span class="math inline">\(N(0,1)\)</span>, standard tables of cumulative normal distributions would yield the probability of <span class="math inline">\(Z\)</span> being greater than any given value, or in turn would give the probability of the estimated value being more than any given distance from the true value of <span class="math inline">\(\beta\)</span>, i.e., <span class="math inline">\(b-\beta\)</span>. However, (3.16) depends upon <span class="math inline">\(\sigma\)</span>, which is unknown. <span class="math inline">\(s^2\)</span> is an unbiased estimator of <span class="math inline">\(\sigma^2\)</span> and is substituted for <span class="math inline">\(\sigma\)</span> in our expression for <span class="math inline">\(\sigma_b\)</span>. However, any inferences employing <span class="math inline">\(s^2\)</span> will not be as precise as they would be if we knew <span class="math inline">\(\sigma^2\)</span> and did not have to rely upon the random variable <span class="math inline">\(s^2\)</span>. In order to allow for this additional imprecision, we do not use probabilities from the normal distribution. Instead, we shall rely upon the <span class="math inline">\(t\)</span>-distribution. The definition of the <span class="math inline">\(t\)</span>-distribution is as follows: if <span class="math inline">\(Z\)</span> is a standard normal variable, i.e., <span class="math inline">\(Z\)</span> is <span class="math inline">\(N(0,1)\)</span>, and if <span class="math inline">\(W^2\)</span> is an independently distributed chisquared with <span class="math inline">\(n-3\)</span> degrees of freedom, then <span class="math inline">\(Z / \sqrt{W^2 /(n-3)}\)</span> is distributed according to the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-3\)</span> degrees of freedom. We have demonstrated that <span class="math inline">\((b-\beta) / \sigma_b\)</span> is <span class="math inline">\(N(0,1)\)</span>. It can further be shown that (Hoel, 1962, pp.&nbsp;262-268) <span class="math display">\[
W^2=\sum e_i^2 / \sigma^2 \quad \text { is } \quad \chi_{n-3}^2 .
\]</span> For <span class="math inline">\(b_2\)</span> we get <span class="math display">\[
\begin{aligned}
t_{b_2} &amp; =\frac{Z}{\sqrt{W^2 /(n-3)}}=\frac{\left(b_2-\beta_2\right) / \sigma_{b_2}}{\sqrt{\sum e_i^2 / \sigma^2(n-3)}} \\
&amp; =\frac{\left(b_2-\beta_2\right)}{(\sigma / n)\left[1 / V_2\left(1-r_{23}^2\right)\right]} \frac{1}{\sqrt{\sum e_i^2} / \sigma \sqrt{n-3}}=\frac{b_2-\beta_2}{(s / n)\left(\left(1 / V_2\right) /\left(1-r_{23}^2\right)\right)} \\
&amp; =\frac{b_2-\beta_2}{s_{b_2}},
\end{aligned}
\]</span> where <span class="math inline">\(s^2=\sum e_i^2 /(n-3)\)</span>. This variable <span class="math inline">\(t_{b_2}\)</span> is distributed as Student’s <span class="math inline">\(t\)</span> with <span class="math inline">\(n-3\)</span> degrees of freedom.</p>
<p><span class="math display">\[
t_b=|b| / s_b&gt;t_{\text {crit }(\alpha / 2, n-3)},
\]</span> <span class="math inline">\(t_{\text {crit }(\alpha / 2, n-3)}\)</span> is the critical value for <span class="math inline">\(n-3\)</span> degrees of freedon ificance level of <span class="math inline">\(\alpha\)</span>. The significance level <span class="math inline">\(\alpha\)</span> is the size of a type I probability of rejecting the null hypothesis when it is in fact ole terms, the further <span class="math inline">\(b\)</span> is from zero (i.e., the higher <span class="math inline">\(t_b\)</span> ), the less lik <span class="math inline">\(\beta\)</span> is really zero. The general form of the hypothesis test for <span class="math inline">\(H_0\)</span> : <span class="math display">\[
t_b=\left|b-\beta^*\right| / s_b .
\]</span> <span class="math inline">\(&gt;t_{\text {crit }(\alpha / 2, n-3)}\)</span>, the null hypothesis is rejected. In other words</p>
</div>
</div>
</div>
</section>
<section id="unabhängigkeit-der-fehler-v8." class="level4" data-number="2.3.4.2">
<h4 data-number="2.3.4.2" class="anchored" data-anchor-id="unabhängigkeit-der-fehler-v8."><span class="header-section-number">2.3.4.2</span> Unabhängigkeit der Fehler (V8.)</h4>
<p>Die Unabhängigkeit der Fehler ist eigentlich nur dann ein echtes Problem, wenn die Fehler in eine Reihenfolge gebracht werden können. Das wiederum passiert eher nur bei Zeitreihen, also wenn die Werte einer Erhebung zeitlich angeordnet sind. Dafür gibt es dann allerdings die recht komplexen Zeitreihenanalysen, die eher Statistik IV im Master darstellen. Wir können uns in der R-Übung mal den Durbin-Watson-Test anschauen (zum Spass die Formel @ref(eq:DWT), wo man schon sieht, dass nicht der Index i für Fälle, sondern t durchläuft für <strong>t</strong>ime), der prüft, ob die Fehler autokorreliert sind, also hoch mit der um eine Zeiteinheit versetzten Version ihrer selbst korrelieren. Was Sie mitnehmen sollten ist, dass sie bei Erhebungen über die Zeit (Longitudinalstudien), noch prüfen müssen, ob bzw. inwieweit die Fehler miteinander korrelieren.</p>
<span class="math display">\[\begin{align}
  d =&amp; \frac{\sum_{i=2}^n(e_i-e_{i-1})^2}{\sum_{i=1}^n e^2_i} \label{eq:DWT}
\end{align}\]</span>


</section>
</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>In einem offiziellen Anmeldeformular, das in Deutschland für Impfungen aufgeschaltet war, stand als dritte Option «Taucher», was der Autor für eine nicht sehr gelungene Übersetzung des Wortes «divers» hält.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Noch besser ist es, wenn die Geschlechterfrage in Fragebögen halboffen gestaltet ist und die offenen Antworten in Dummys kodiert werden.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Wenn nur kategoriale Variablen in der oder den UVs stecken, haben wir das, was mal Varianzanalyse genannt wurde.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script>

/* update total correct if #webex-total_correct exists */
update_total_correct = function() {
  console.log("webex: update total_correct");

  if (t = document.getElementById("webex-total_correct")) {
    var correct = document.getElementsByClassName("webex-correct").length;
    var solvemes = document.getElementsByClassName("webex-solveme").length;
    var radiogroups = document.getElementsByClassName("webex-radiogroup").length;
    var selects = document.getElementsByClassName("webex-select").length;
    
    t.innerHTML = correct + " of " + (solvemes + radiogroups + selects) + " correct";
  }
}

/* webex-solution button toggling function */
b_func = function() {
  console.log("webex: toggle hide");
  
  var cl = this.parentElement.classList;
  if (cl.contains('open')) {
    cl.remove("open");
  } else {
    cl.add("open");
  }
}

/* function for checking solveme answers */
solveme_func = function(e) {
  console.log("webex: check solveme");

  var real_answers = JSON.parse(this.dataset.answer);
  var my_answer = this.value;
  var cl = this.classList;
  if (cl.contains("ignorecase")) {
    my_answer = my_answer.toLowerCase();
  }
  if (cl.contains("nospaces")) {
    my_answer = my_answer.replace(/ /g, "")
  }

  if (my_answer == "") {
    cl.remove("webex-correct");
    cl.remove("webex-incorrect");
  } else if (real_answers.includes(my_answer)) {
    cl.add("webex-correct");
    cl.remove("webex-incorrect");
  } else {
    cl.add("webex-incorrect");
    cl.remove("webex-correct");
  }

  // match numeric answers within a specified tolerance
  if(this.dataset.tol > 0){
    var tol = JSON.parse(this.dataset.tol);
    var matches = real_answers.map(x => Math.abs(x - my_answer) < tol)
    if (matches.reduce((a, b) => a + b, 0) > 0) {
      cl.add("webex-correct");
    } else {
      cl.remove("webex-correct");
    }
  }

  // added regex bit
  if (cl.contains("regex")){
    answer_regex = RegExp(real_answers.join("|"))
    if (answer_regex.test(my_answer)) {
      cl.add("webex-correct");
    }
  }

  update_total_correct();
}

/* function for checking select answers */
select_func = function(e) {
  console.log("webex: check select");
  
  var cl = this.classList
  
  /* add style */
  cl.remove("webex-incorrect");
  cl.remove("webex-correct");
  if (this.value == "answer") {
    cl.add("webex-correct");
  } else if (this.value != "blank") {
    cl.add("webex-incorrect");
  }
  
  update_total_correct();
}

/* function for checking radiogroups answers */
radiogroups_func = function(e) {
  console.log("webex: check radiogroups");

  var checked_button = document.querySelector('input[name=' + this.id + ']:checked');
  var cl = checked_button.parentElement.classList;
  var labels = checked_button.parentElement.parentElement.children;
  
  /* get rid of styles */
  for (i = 0; i < labels.length; i++) {
    labels[i].classList.remove("webex-incorrect");
    labels[i].classList.remove("webex-correct");
  }
  
  /* add style */
  if (checked_button.value == "answer") {
    cl.add("webex-correct");
  } else {
    cl.add("webex-incorrect");
  }
  
  update_total_correct();
}

window.onload = function() {
  console.log("onload");
  /* set up solution buttons */
  var buttons = document.getElementsByTagName("button");

  for (var i = 0; i < buttons.length; i++) {
    if (buttons[i].parentElement.classList.contains('webex-solution')) {
      buttons[i].onclick = b_func;
    }
  }

  /* set up webex-solveme inputs */
  var solveme = document.getElementsByClassName("webex-solveme");

  for (var i = 0; i < solveme.length; i++) {
    /* make sure input boxes don't auto-anything */
    solveme[i].setAttribute("autocomplete","off");
    solveme[i].setAttribute("autocorrect", "off");
    solveme[i].setAttribute("autocapitalize", "off");
    solveme[i].setAttribute("spellcheck", "false");
    solveme[i].value = "";

    /* adjust answer for ignorecase or nospaces */
    var cl = solveme[i].classList;
    var real_answer = solveme[i].dataset.answer;
    if (cl.contains("ignorecase")) {
      real_answer = real_answer.toLowerCase();
    }
    if (cl.contains("nospaces")) {
      real_answer = real_answer.replace(/ /g, "");
    }
    solveme[i].dataset.answer = real_answer;

    /* attach checking function */
    solveme[i].onkeyup = solveme_func;
    solveme[i].onchange = solveme_func;
  }
  
  /* set up radiogroups */
  var radiogroups = document.getElementsByClassName("webex-radiogroup");
  for (var i = 0; i < radiogroups.length; i++) {
    radiogroups[i].onchange = radiogroups_func;
  }
  
  /* set up selects */
  var selects = document.getElementsByClassName("webex-select");
  for (var i = 0; i < selects.length; i++) {
    selects[i].onchange = select_func;
  }

  update_total_correct();
}

</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Kopiert");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Kopiert");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./01_Wiederholung.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Was bisher geschah</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./03_Regression_in_R.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Regression in R</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>